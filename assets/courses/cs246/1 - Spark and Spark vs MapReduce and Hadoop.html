
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <!-- common.css -->
      <style>* {-webkit-tap-highlight-color: rgba(0,0,0,0);}html {-webkit-text-size-adjust: none;}body {font-family: -apple-system, Helvetica, Arial, sans-serif;margin: 0;padding: 20px;color: #333;word-wrap: break-word;}h1, h2, h3, h4, h5, h6 {line-height: 1.1;}img {max-width: 100% !important;height: auto;}blockquote {margin: 0;padding: 0 15px;color: #777;border-left: 4px solid #ddd;}hr {background-color: #ddd;border: 0;height: 1px;margin: 15px 0;}code {font-family: Menlo, Consolas, 'Ubuntu Mono', Monaco, 'source-code-pro', monospace;line-height: 1.4;margin: 0;padding: 0.2em 0;font-size: 90%;background-color: rgba(0,0,0,0.04);border-radius: 3px;}pre > code {margin: 0;padding: 0;font-size: 100%;word-break: normal;background: transparent;border: 0;}ol {list-style-type: decimal;}ol ol, ul ol {list-style-type: lower-latin;}ol ol ol, ul ol ol, ul ul ol, ol ul ol {list-style-type: lower-roman;}table {border-spacing: 0;border-collapse: collapse;margin-top: 0;margin-bottom: 16px;}table th {font-weight: bold;}table th, table td {padding: 6px 13px;border: 1px solid #ddd;}table tr {border-top: 1px solid #ccc;}table tr:nth-child(even) {background-color: #f8f8f8;}input[type="checkbox"] {cursor: default;margin-right: 0.5em;font-size: 13px;}.task-list-item {list-style-type: none;}.task-list-item+.task-list-item {margin-top: 3px;}.task-list-item input {float: left;margin: 0.3em 1em 0.25em -1.6em;vertical-align: middle;}#tag-field {margin: 8px 2px 10px;}#tag-field .tag {display: inline-block;background: #cadff3;border-radius: 4px;padding: 1px 8px;color: black;font-size: 12px;margin-right: 10px;line-height: 1.4;}</style>
      <!-- ace-static.css -->
      <style>.ace_static_highlight {white-space: pre-wrap;}.ace_static_highlight .ace_gutter {width: 2em;text-align: right;padding: 0 3px 0 0;margin-right: 3px;}.ace_static_highlight.ace_show_gutter > .ace_line {padding-left: 2.6em;}.ace_static_highlight .ace_line {position: relative;}.ace_static_highlight .ace_gutter-cell {-moz-user-select: -moz-none;-khtml-user-select: none;-webkit-user-select: none;user-select: none;top: 0;bottom: 0;left: 0;position: absolute;}.ace_static_highlight .ace_gutter-cell:before {content: counter(ace_line, decimal);counter-increment: ace_line;}.ace_static_highlight {counter-reset: ace_line;}</style>
      <style>.ace-chrome .ace_gutter {background: #ebebeb;color: #333;overflow : hidden;}.ace-chrome .ace_print-margin {width: 1px;background: #e8e8e8;}.ace-chrome {background-color: #FFFFFF;color: black;}.ace-chrome .ace_cursor {color: black;}.ace-chrome .ace_invisible {color: rgb(191, 191, 191);}.ace-chrome .ace_constant.ace_buildin {color: rgb(88, 72, 246);}.ace-chrome .ace_constant.ace_language {color: rgb(88, 92, 246);}.ace-chrome .ace_constant.ace_library {color: rgb(6, 150, 14);}.ace-chrome .ace_invalid {background-color: rgb(153, 0, 0);color: white;}.ace-chrome .ace_fold {}.ace-chrome .ace_support.ace_function {color: rgb(60, 76, 114);}.ace-chrome .ace_support.ace_constant {color: rgb(6, 150, 14);}.ace-chrome .ace_support.ace_type,.ace-chrome .ace_support.ace_class.ace-chrome .ace_support.ace_other {color: rgb(109, 121, 222);}.ace-chrome .ace_variable.ace_parameter {font-style:italic;color:#FD971F;}.ace-chrome .ace_keyword.ace_operator {color: rgb(104, 118, 135);}.ace-chrome .ace_comment {color: #236e24;}.ace-chrome .ace_comment.ace_doc {color: #236e24;}.ace-chrome .ace_comment.ace_doc.ace_tag {color: #236e24;}.ace-chrome .ace_constant.ace_numeric {color: rgb(0, 0, 205);}.ace-chrome .ace_variable {color: rgb(49, 132, 149);}.ace-chrome .ace_xml-pe {color: rgb(104, 104, 91);}.ace-chrome .ace_entity.ace_name.ace_function {color: #0000A2;}.ace-chrome .ace_heading {color: rgb(12, 7, 255);}.ace-chrome .ace_list {color:rgb(185, 6, 144);}.ace-chrome .ace_marker-layer .ace_selection {background: rgb(181, 213, 255);}.ace-chrome .ace_marker-layer .ace_step {background: rgb(252, 255, 0);}.ace-chrome .ace_marker-layer .ace_stack {background: rgb(164, 229, 101);}.ace-chrome .ace_marker-layer .ace_bracket {margin: -1px 0 0 -1px;border: 1px solid rgb(192, 192, 192);}.ace-chrome .ace_marker-layer .ace_active-line {background: rgba(0, 0, 0, 0.07);}.ace-chrome .ace_gutter-active-line {background-color : #dcdcdc;}.ace-chrome .ace_marker-layer .ace_selected-word {background: rgb(250, 250, 255);border: 1px solid rgb(200, 200, 250);}.ace-chrome .ace_storage,.ace-chrome .ace_keyword,.ace-chrome .ace_meta.ace_tag {color: rgb(147, 15, 128);}.ace-chrome .ace_string.ace_regex {color: rgb(255, 0, 0)}.ace-chrome .ace_string {color: #1A1AA6;}.ace-chrome .ace_entity.ace_other.ace_attribute-name {color: #994409;}.ace-chrome .ace_indent-guide {background: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAACCAYAAACZgbYnAAAAE0lEQVQImWP4////f4bLly//BwAmVgd1/w11/gAAAABJRU5ErkJggg==") right repeat-y;}</style>
      <!-- export.css -->
      <style>
        body{margin:0 auto;max-width:800px;line-height:1.4}
        #nav{margin:5px 0 10px;font-size:15px}
        #titlearea{border-bottom:1px solid #ccc;font-size:17px;padding:10px 0;}
        #contentarea{font-size:15px;margin:16px 0}
        .cell{outline:0;min-height:20px;margin:5px 0;padding:5px 0;}
        .code-cell{font-family:Menlo,Consolas,'Ubuntu Mono',Monaco,'source-code-pro',monospace;font-size:12px;}
        .latex-cell{white-space:pre-wrap;}
      </style>
      <!-- User CSS -->
      <style> .text-cell {font-size: 15px;}.code-cell {font-size: 12px;}.markdown-cell {font-size: 15px;}.latex-cell {font-size: 15px;}</style>
    </head>
    <body>
      
      <div id="titlearea">
        <h2>Lecture 1a - Spark and Spark vs MapReduce</h2>
      </div>
      <div id="contentarea"><div class="cell markdown-cell"><h1>Lecture 1a - Spark and Spark vs MapReduce</h1>
<p>Generally Spark is faster with Hadoop but with caveats<br>
-	Spark can process data in memory, Hadoop persists it back to disk after map and reduce.<br>
- So Spark generally outperforms MapReduce, but requires a lot of memory. If there is not enough memory, spark degrades.<br>
- MapReduce runs well along size other services, and woks well for the 1-pass jobs it was designed for.<br>
Spark is easier to program, spark is more general.<br>
Spark assumed your entire data fits in memory. MapReduce needs zero memory.</p>
<p>Hive is a map reduce SQL (bigger data) and SparkSQL is a spark based SQL.</p>
<h2>Problems suitable for MapReduce</h2>
<p>One pass problems. Use MapReduce or Spark.<br>
- Ee have a large file (large web corpus), and we want to count something or<br>
- Link analysis and graph processing<br>
- Machine learning algos<br>
- Statistical machine translation<br>
- Giant table joins</p>
<h2>Problems not suitable for MapReduce. Use Spark.</h2>
<p>MapReduce is inefficient when you have random accesses<br>
- Graphs<br>
- Interdependent data<br>
- Machine learning, Comparisons of many pairs of items<br>
- In MapReduce, we quantify the cost of an algorithm using<br>
- 1. Communication cost - total I/O<br>
- Elapsed communication cost<br>
- Elapsed computation cost<br>
When you make MapReduce jobs in the real world, you really worry about the intermediate data size. You don’t want that to explode.</p>
<h1>MapReduce</h1>
<ul>
<li>Designed for Easy Parallel Programming</li>
<li>Invisible management of hardware and software failures</li>
<li>Easy management of very laser scale data</li>
<li>Hadoop, Spark, Flink</li>
</ul>
<h2>3 Steps of MapReduce</h2>
<ul>
<li>Map
<ul>
<li><strong>parallel operation</strong></li>
<li>Apply a <strong>user-written map function</strong> to each input element.</li>
<li>Mapper applies the map function to a single element
<ul>
<li>many mappers group in a map task</li>
</ul>
</li>
<li>outputs set of key value pairs</li>
</ul>
</li>
<li>Group by Key (<strong>bottleneck in practice</strong>)
<ul>
<li>system groups all k,v pairs by value, outputting key, (list of values) pairs.</li>
<li>System does this, user does not do anything.</li>
<li>Group occurs across chunks</li>
</ul>
</li>
<li>Reduce <strong>parallel operation</strong>
<ul>
<li><strong>user written reduce function</strong> is applied to each (key-list of values)<br>
All the mappers have to finish before we can start reducing. So we may start all the map operations on multiple chunks and only keep the fastest.</li>
</ul>
</li>
</ul>
<p>MapEnvironment takes care of<br>
- Partitioning the input data<br>
- Scheduling the program’s execution across a set of machines<br>
- Performing the group by key step<br>
- handling machine failures<br>
- managing inter-machine communication</p>
<p>Dealing with failures<br>
Map worker failure<br>
Reduce worker failures <strong>harder</strong>:<br>
- Only in-progress tasks need to be reset and reduce task is started</p>
<h1>Spark</h1>
<p>Spark is a fast cluster computing system, high level APIs in Java, Scala, Python, R. Built in Scala (and on a JVM).<br>
- can run as a standalone or on top of Hadoop YARN (Custer Manager), where it can read data directly from HDFS</p>
<ul>
<li>MapReduce is Batch Processing</li>
<li>Apache Storm is Real-time Processing</li>
<li>Spark you can do both.</li>
</ul>
<h2>Spark Core</h2>
<p>Add-ons: Spark SQL, Spark Streaming, MLib, GraphX<br>
- Spark Streaming is not a real real time processing system like Apache Storm, instead based on micro-batching, but close enough for 95% scenarios.</p>
<h3>Spark Terms</h3>
<ul>
<li>RDD - Data lives here. RDD data is immutable.</li>
<li>DAG - When you run an app in Spark, it constructs a compute graph (DAG) which is the execution flow</li>
<li>SparkContext - You have a driver and the driver initiates the spark context and the spark context does a lot of the orchestration within the spark cluster</li>
<li>Transformations - When you load data from a data storage to an RDD, since RDDs are immutable, when you do a map or function operation it creates a new RDD, this is called a transformation.</li>
<li>Actions - Anything within Spark is done with lazy loading. When the DAG is created, no computation is performed until it is actually required. When it is necessary for the computation to be performed (it has not been calculated before and cached as a transformation), it is called an action.</li>
<li>The DAG is comprised of many, many transformations and a few actions.</li>
</ul>
<h3>Spark Components</h3>
<ul>
<li>Driver Program
<ul>
<li>Spark Context. The main program or client/terminal is the spark context</li>
</ul>
</li>
<li>Cluster Manager (default is Spark manager, you can switch to Yarn or Apache Mesos to have a manager with special features, such as putting tasks into a queue)</li>
<li>Worker Node
<ul>
<li>Cache</li>
<li>Executor</li>
<li>Task</li>
<li>Task</li>
</ul>
</li>
<li>Worker Node
<ul>
<li>Cache</li>
<li>Executor
<ul>
<li>Task</li>
<li>Task</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3>Differences between Spark and Map-Reduce</h3>
<ul>
<li>It runs in-memory on the cluster, whereas MapReduce writes to disk after every computation</li>
<li>It follows DAG processing and doesn’t have to follow repeated map-reduce structure</li>
<li>Spark requires <em>a lot of memory</em> to function. If Spark runs on Hadoop YARN with other resource-demanding services, or if the data is too big to fit entirely into the memory, then there could be major performance degradations for Spark. Spark has the upper hand as long as we’re talking about iterative computations that need to pass over the same data many times. But when it comes to one-pass ETL-like jobs, for example, data transformation or <a href="https://www.xplenty.com/signup/">data integration</a> , then MapReduce is the deal—this is what it was designed for. **Bottom line:**Spark performs better when all the data fits in the memory, especially on dedicated clusters; Hadoop MapReduce is designed for data that doesn’t fit in the memory and it can run well alongside other services.</li>
<li>In comparison to Hadoop’s MapReduce, Spark uses significantly more resources, which can interfere with other tasks that might be trying to use the cluster at the time. In essence, Spark might be a less considerate neighbor than other components that can operate on the Hadoop stack.</li>
</ul>
<p>See also:</p>
<ul>
<li><a href="bear://x-callback-url/open-note?id=CAB807C7-205C-4516-92F6-5FBF021DE6FA-10200-0000B138F7A869BF">Hadoop, Storm, Samza, Spark, and Flink: Big Data Frameworks Compared</a></li>
</ul>
</div></div>
    </body>
    </html>
  