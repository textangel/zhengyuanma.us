
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <!-- common.css -->
      <style>* {-webkit-tap-highlight-color: rgba(0,0,0,0);}html {-webkit-text-size-adjust: none;}body {font-family: -apple-system, Helvetica, Arial, sans-serif;margin: 0;padding: 20px;color: #333;word-wrap: break-word;}h1, h2, h3, h4, h5, h6 {line-height: 1.1;}img {max-width: 100% !important;height: auto;}blockquote {margin: 0;padding: 0 15px;color: #777;border-left: 4px solid #ddd;}hr {background-color: #ddd;border: 0;height: 1px;margin: 15px 0;}code {font-family: Menlo, Consolas, 'Ubuntu Mono', Monaco, 'source-code-pro', monospace;line-height: 1.4;margin: 0;padding: 0.2em 0;font-size: 90%;background-color: rgba(0,0,0,0.04);border-radius: 3px;}pre > code {margin: 0;padding: 0;font-size: 100%;word-break: normal;background: transparent;border: 0;}ol {list-style-type: decimal;}ol ol, ul ol {list-style-type: lower-latin;}ol ol ol, ul ol ol, ul ul ol, ol ul ol {list-style-type: lower-roman;}table {border-spacing: 0;border-collapse: collapse;margin-top: 0;margin-bottom: 16px;}table th {font-weight: bold;}table th, table td {padding: 6px 13px;border: 1px solid #ddd;}table tr {border-top: 1px solid #ccc;}table tr:nth-child(even) {background-color: #f8f8f8;}input[type="checkbox"] {cursor: default;margin-right: 0.5em;font-size: 13px;}.task-list-item {list-style-type: none;}.task-list-item+.task-list-item {margin-top: 3px;}.task-list-item input {float: left;margin: 0.3em 1em 0.25em -1.6em;vertical-align: middle;}#tag-field {margin: 8px 2px 10px;}#tag-field .tag {display: inline-block;background: #cadff3;border-radius: 4px;padding: 1px 8px;color: black;font-size: 12px;margin-right: 10px;line-height: 1.4;}</style>
      <!-- ace-static.css -->
      <style>.ace_static_highlight {white-space: pre-wrap;}.ace_static_highlight .ace_gutter {width: 2em;text-align: right;padding: 0 3px 0 0;margin-right: 3px;}.ace_static_highlight.ace_show_gutter > .ace_line {padding-left: 2.6em;}.ace_static_highlight .ace_line {position: relative;}.ace_static_highlight .ace_gutter-cell {-moz-user-select: -moz-none;-khtml-user-select: none;-webkit-user-select: none;user-select: none;top: 0;bottom: 0;left: 0;position: absolute;}.ace_static_highlight .ace_gutter-cell:before {content: counter(ace_line, decimal);counter-increment: ace_line;}.ace_static_highlight {counter-reset: ace_line;}</style>
      <style>.ace-chrome .ace_gutter {background: #ebebeb;color: #333;overflow : hidden;}.ace-chrome .ace_print-margin {width: 1px;background: #e8e8e8;}.ace-chrome {background-color: #FFFFFF;color: black;}.ace-chrome .ace_cursor {color: black;}.ace-chrome .ace_invisible {color: rgb(191, 191, 191);}.ace-chrome .ace_constant.ace_buildin {color: rgb(88, 72, 246);}.ace-chrome .ace_constant.ace_language {color: rgb(88, 92, 246);}.ace-chrome .ace_constant.ace_library {color: rgb(6, 150, 14);}.ace-chrome .ace_invalid {background-color: rgb(153, 0, 0);color: white;}.ace-chrome .ace_fold {}.ace-chrome .ace_support.ace_function {color: rgb(60, 76, 114);}.ace-chrome .ace_support.ace_constant {color: rgb(6, 150, 14);}.ace-chrome .ace_support.ace_type,.ace-chrome .ace_support.ace_class.ace-chrome .ace_support.ace_other {color: rgb(109, 121, 222);}.ace-chrome .ace_variable.ace_parameter {font-style:italic;color:#FD971F;}.ace-chrome .ace_keyword.ace_operator {color: rgb(104, 118, 135);}.ace-chrome .ace_comment {color: #236e24;}.ace-chrome .ace_comment.ace_doc {color: #236e24;}.ace-chrome .ace_comment.ace_doc.ace_tag {color: #236e24;}.ace-chrome .ace_constant.ace_numeric {color: rgb(0, 0, 205);}.ace-chrome .ace_variable {color: rgb(49, 132, 149);}.ace-chrome .ace_xml-pe {color: rgb(104, 104, 91);}.ace-chrome .ace_entity.ace_name.ace_function {color: #0000A2;}.ace-chrome .ace_heading {color: rgb(12, 7, 255);}.ace-chrome .ace_list {color:rgb(185, 6, 144);}.ace-chrome .ace_marker-layer .ace_selection {background: rgb(181, 213, 255);}.ace-chrome .ace_marker-layer .ace_step {background: rgb(252, 255, 0);}.ace-chrome .ace_marker-layer .ace_stack {background: rgb(164, 229, 101);}.ace-chrome .ace_marker-layer .ace_bracket {margin: -1px 0 0 -1px;border: 1px solid rgb(192, 192, 192);}.ace-chrome .ace_marker-layer .ace_active-line {background: rgba(0, 0, 0, 0.07);}.ace-chrome .ace_gutter-active-line {background-color : #dcdcdc;}.ace-chrome .ace_marker-layer .ace_selected-word {background: rgb(250, 250, 255);border: 1px solid rgb(200, 200, 250);}.ace-chrome .ace_storage,.ace-chrome .ace_keyword,.ace-chrome .ace_meta.ace_tag {color: rgb(147, 15, 128);}.ace-chrome .ace_string.ace_regex {color: rgb(255, 0, 0)}.ace-chrome .ace_string {color: #1A1AA6;}.ace-chrome .ace_entity.ace_other.ace_attribute-name {color: #994409;}.ace-chrome .ace_indent-guide {background: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAACCAYAAACZgbYnAAAAE0lEQVQImWP4////f4bLly//BwAmVgd1/w11/gAAAABJRU5ErkJggg==") right repeat-y;}</style>
      <!-- export.css -->
      <style>
        body{margin:0 auto;max-width:800px;line-height:1.4}
        #nav{margin:5px 0 10px;font-size:15px}
        #titlearea{border-bottom:1px solid #ccc;font-size:17px;padding:10px 0;}
        #contentarea{font-size:15px;margin:16px 0}
        .cell{outline:0;min-height:20px;margin:5px 0;padding:5px 0;}
        .code-cell{font-family:Menlo,Consolas,'Ubuntu Mono',Monaco,'source-code-pro',monospace;font-size:12px;}
        .latex-cell{white-space:pre-wrap;}
      </style>
      <!-- User CSS -->
      <style> .text-cell {font-size: 15px;}.code-cell {font-size: 12px;}.markdown-cell {font-size: 15px;}.latex-cell {font-size: 15px;}</style>
    </head>
    <body>
      <div id="titlearea">
        <h2>CS224n - *Lecture 15: Natural Language Generation (NLG)</h2>
      </div>
      <div id="contentarea"><div class="cell text-cell"><img src="resources/FE3E8589E659BC1B8B67D50C506F788C.png" alt="Screenshot 2020-01-29 at 9.53.55 PM.png" width="597" height="410"><div><img src="resources/E797407036FC7A2CDBFEECAEEC2B9265.png" alt="Screenshot 2020-01-29 at 9.55.59 PM.png" width="602" height="108"><br></div><div><img src="resources/5ADA9E4CDE645D37177280394F3EA584.png" alt="Screenshot 2020-01-29 at 9.56.22 PM.png" width="608" height="326"><br></div><div><br></div><div>&nbsp;</div><div style="font-size: 15px;"><b>Teacher Forcing</b></div><div>During training, we feed the gold (aka reference) target sentence into the decoder, regardless of what the decoder predicts. This training method is called Teacher Forcing.</div><div><br></div><div><img src="resources/C384BCDB6B2B98B8DB015A8F813A686D.png" alt="Screenshot 2020-01-29 at 9.57.42 PM.png" width="625" height="457"><br></div><div><br></div><div style="font-size: 17px;"><b></b></div></div><div class="cell text-cell"><div style="font-size: 17px;"><b><br></b></div><div style="font-size: 17px;"><b>Decoding Algorithms</b></div><div style="font-size: 12px;"><b>- Greedy Decoding</b></div><div style="font-size: 12px;"><b>- Beam Search</b></div><div style="font-size: 12px;"><br></div><div style="font-size: 12px;">What’s the effect of changing beam size k?</div><div style="font-size: 12px;">- Small k has similar problems to greedy decoding - incorrect output</div><div style="font-size: 12px;">- Larger k considers more hypothesis. This could be potentially expensive.&nbsp;</div><div style="font-size: 12px;"><ul><li>&nbsp;In NMT, increasing <i>k</i> too much decreases BLEU score, becasue large-<i>k</i> beam search produces too short translations!<br></li><li>In open-ended tasks like chit-chat dialogue, large <i>k</i> can make ourput more generic.</li></ul></div><div style="font-size: 12px;"><img src="resources/EFAA460733FFBF828BC5C783301E5E0F.png" alt="Screenshot 2020-01-30 at 3.31.12 PM.png" width="611" height="426"><br></div><div style="font-size: 12px;"><br></div><div style="font-size: 12px;"><b>Sampling-based decoding</b></div><div style="font-size: 12px;">Sampling-based decoding is <b>more efficient</b>&nbsp;than beam search becasue there are no multiple hypotheses to track at each step.</div><div style="font-size: 12px;"><br></div><div style="font-size: 12px;">Pure sampling&nbsp;</div><div style="font-size: 12px;">&nbsp; - On each step t, randomly sample from the probability ditribution P_t to obtain your next word. Like greedy but sample instead of argmax.</div><div style="font-size: 12px;"><br></div><div style="font-size: 12px;">Top-n sampling</div><div style="font-size: 12px;">&nbsp; - On each step t, randomly sample from P_t, restricted to jsut the top-n most probable words. Like pure sampling, but truncate the proabbility distribution.</div><div style="font-size: 12px;">&nbsp; - n=1 is greedy search, n=V is pure sampling</div><div style="font-size: 12px;">&nbsp; - Increase n to get more diverse/risky output</div><div style="font-size: 12px;">&nbsp; - Decrease n to get more generic/safe output.</div><div style="font-size: 12px;"><br></div><div style="font-size: 12px;"><br></div><div style="font-size: 12px;"></div></div><div class="cell markdown-cell"><h4>Softmax Temperature</h4>
<p>Softmax temperature is not a decoding algo, its a method that can be used with any decoding algo to control diversity of output.</p>
<p>On timestep <span class="MathJax" id="MathJax-Element-157-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-5724" style="width: 0.391em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.338em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.819em, 1000em, 2.714em, -0.469em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5725"><span class="mi" id="MathJax-Span-5726" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.018em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.743em; vertical-align: -0.075em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-157">t</script>, the LM computes a prob dist <span class="MathJax" id="MathJax-Element-158-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-5727" style="width: 1.078em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.957em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.374em, 1000em, 2.523em, -0.507em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-5728"><span class="msubsup" id="MathJax-Span-5729"><span style="display: inline-block; position: relative; width: 0.92em; height: 0px;"><span style="position: absolute; clip: rect(1.712em, 1000em, 2.703em, -0.507em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5730" style="font-family: STIXGeneral-Italic;">P</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.619em;"><span class="mi" id="MathJax-Span-5731" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.013em;"></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.025em; vertical-align: -0.238em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-158">P_t</script> by applying the softmax function to a vector of scores <span class="MathJax" id="MathJax-Element-159-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-5732" style="width: 3.578em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.209em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.507em, 1000em, 2.73em, -0.491em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5733"><span class="mi" id="MathJax-Span-5734" style="font-family: STIXGeneral-Italic;">s</span><span class="mo" id="MathJax-Span-5735" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">∈</span><span class="msubsup" id="MathJax-Span-5736" style="padding-left: 0.313em;"><span style="display: inline-block; position: relative; width: 1.483em; height: 0px;"><span style="position: absolute; clip: rect(1.712em, 1000em, 2.703em, -0.52em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5737" style="font-family: STIXGeneral-Italic;">R</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.689em; left: 0.619em;"><span class="texatom" id="MathJax-Span-5738"><span class="mrow" id="MathJax-Span-5739"><span class="texatom" id="MathJax-Span-5740"><span class="mrow" id="MathJax-Span-5741"><span class="mo" id="MathJax-Span-5742" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">|</span></span></span><span class="mi" id="MathJax-Span-5743" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span class="texatom" id="MathJax-Span-5744"><span class="mrow" id="MathJax-Span-5745"><span class="mo" id="MathJax-Span-5746" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">|</span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.107em; vertical-align: -0.092em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-159">s \in R^{|V|}</script>.</p>
<p></p><div class="MathJax_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax" id="MathJax-Element-160-Frame" style=""><nobr><span class="math" id="MathJax-Span-5747" style="width: 11.641em; display: inline-block;"><span style="display: inline-block; position: relative; width: 10.473em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(0.991em, 1000em, 3.76em, -0.507em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5748"><span class="msubsup" id="MathJax-Span-5749"><span style="display: inline-block; position: relative; width: 0.92em; height: 0px;"><span style="position: absolute; clip: rect(1.712em, 1000em, 2.703em, -0.507em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5750" style="font-family: STIXGeneral-Italic;">P</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.619em;"><span class="mi" id="MathJax-Span-5751" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.013em;"></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-5752" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-5753" style="font-family: STIXGeneral-Italic;">w</span><span class="mo" id="MathJax-Span-5754" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-5755" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">=</span><span class="mfrac" id="MathJax-Span-5756" style="padding-left: 0.313em;"><span style="display: inline-block; position: relative; width: 6.595em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(1.689em, 1000em, 2.92em, -0.482em); top: -3.232em; left: 50%; margin-left: -1.577em;"><span class="mrow" id="MathJax-Span-5757"><span class="mi" id="MathJax-Span-5758" style="font-family: STIXGeneral-Regular;">exp</span><span class="mo" id="MathJax-Span-5759"></span><span class="mo" id="MathJax-Span-5760" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-5761"><span style="display: inline-block; position: relative; width: 1.032em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5762" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-5763" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">w</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-5764" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; clip: rect(1.604em, 1000em, 3.018em, -0.449em); top: -1.792em; left: 50%; margin-left: -3.238em;"><span class="mrow" id="MathJax-Span-5765"><span class="munderover" id="MathJax-Span-5766"><span style="display: inline-block; position: relative; width: 2.834em; height: 0px;"><span style="position: absolute; clip: rect(1.548em, 1000em, 2.907em, -0.449em); top: -2.477em; left: 0em;"><span class="mo" id="MathJax-Span-5767" style="font-family: STIXGeneral-Regular; vertical-align: -0.002em;">∑</span><span style="display: inline-block; width: 0px; height: 2.477em;"></span></span><span style="position: absolute; top: -2.012em; left: 0.957em;"><span class="texatom" id="MathJax-Span-5768"><span class="mrow" id="MathJax-Span-5769"><span class="msup" id="MathJax-Span-5770"><span style="display: inline-block; position: relative; width: 0.785em; height: 0px;"><span style="position: absolute; clip: rect(1.828em, 1000em, 2.49em, -0.496em); top: -2.309em; left: 0em;"><span class="mi" id="MathJax-Span-5771" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">w</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; top: -2.4em; left: 0.507em;"><span class="mo" id="MathJax-Span-5772" style="font-size: 50%; font-family: STIXVariants;">′</span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span><span class="mo" id="MathJax-Span-5773" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∈</span><span class="mi" id="MathJax-Span-5774" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mi" id="MathJax-Span-5775" style="font-family: STIXGeneral-Regular; padding-left: 0.188em;">exp</span><span class="mo" id="MathJax-Span-5776"></span><span class="mo" id="MathJax-Span-5777" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-5778"><span style="display: inline-block; position: relative; width: 1.31em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5779" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -3.848em; left: 0.45em;"><span class="texatom" id="MathJax-Span-5780"><span class="mrow" id="MathJax-Span-5781"><span class="msup" id="MathJax-Span-5782"><span style="display: inline-block; position: relative; width: 0.785em; height: 0px;"><span style="position: absolute; clip: rect(1.828em, 1000em, 2.49em, -0.496em); top: -2.309em; left: 0em;"><span class="mi" id="MathJax-Span-5783" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">w</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; top: -2.4em; left: 0.507em;"><span class="mo" id="MathJax-Span-5784" style="font-size: 50%; font-family: STIXVariants;">′</span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="mo" id="MathJax-Span-5785" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; clip: rect(0.831em, 1000em, 1.239em, -0.507em); top: -1.29em; left: 0em;"><span style="border-left-width: 6.595em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0em;"></span><span style="display: inline-block; width: 0px; height: 1.07em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 2.823em; vertical-align: -1.236em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-160">P_t(w) = \frac{\exp(s_w)}{\sum_{w' \in V} \exp(s_{w'})}</script><p></p>
<p>You can apply a temperature hyperparameter <span class="MathJax" id="MathJax-Element-161-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-5786" style="width: 0.516em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.45em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.937em, 1000em, 2.714em, -0.495em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5787"><span class="mi" id="MathJax-Span-5788" style="font-family: STIXGeneral-Italic;">τ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.016em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.612em; vertical-align: -0.075em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-161">\tau</script> to the softmax<br>
</p><div class="MathJax_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax" id="MathJax-Element-162-Frame" style=""><nobr><span class="math" id="MathJax-Span-5789" style="width: 12.453em; display: inline-block;"><span style="display: inline-block; position: relative; width: 11.205em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(0.991em, 1000em, 3.76em, -0.507em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5790"><span class="msubsup" id="MathJax-Span-5791"><span style="display: inline-block; position: relative; width: 0.92em; height: 0px;"><span style="position: absolute; clip: rect(1.712em, 1000em, 2.703em, -0.507em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5792" style="font-family: STIXGeneral-Italic;">P</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.619em;"><span class="mi" id="MathJax-Span-5793" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.013em;"></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-5794" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-5795" style="font-family: STIXGeneral-Italic;">w</span><span class="mo" id="MathJax-Span-5796" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-5797" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">=</span><span class="mfrac" id="MathJax-Span-5798" style="padding-left: 0.313em;"><span style="display: inline-block; position: relative; width: 7.327em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(1.689em, 1000em, 2.92em, -0.482em); top: -3.232em; left: 50%; margin-left: -1.943em;"><span class="mrow" id="MathJax-Span-5799"><span class="mi" id="MathJax-Span-5800" style="font-family: STIXGeneral-Regular;">exp</span><span class="mo" id="MathJax-Span-5801"></span><span class="mo" id="MathJax-Span-5802" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-5803"><span style="display: inline-block; position: relative; width: 1.032em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5804" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-5805" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">w</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="texatom" id="MathJax-Span-5806"><span class="mrow" id="MathJax-Span-5807"><span class="mo" id="MathJax-Span-5808" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mi" id="MathJax-Span-5809" style="font-family: STIXGeneral-Italic;">τ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.016em;"></span></span><span class="mo" id="MathJax-Span-5810" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; clip: rect(1.604em, 1000em, 3.018em, -0.449em); top: -1.792em; left: 50%; margin-left: -3.604em;"><span class="mrow" id="MathJax-Span-5811"><span class="munderover" id="MathJax-Span-5812"><span style="display: inline-block; position: relative; width: 2.834em; height: 0px;"><span style="position: absolute; clip: rect(1.548em, 1000em, 2.907em, -0.449em); top: -2.477em; left: 0em;"><span class="mo" id="MathJax-Span-5813" style="font-family: STIXGeneral-Regular; vertical-align: -0.002em;">∑</span><span style="display: inline-block; width: 0px; height: 2.477em;"></span></span><span style="position: absolute; top: -2.012em; left: 0.957em;"><span class="texatom" id="MathJax-Span-5814"><span class="mrow" id="MathJax-Span-5815"><span class="msup" id="MathJax-Span-5816"><span style="display: inline-block; position: relative; width: 0.785em; height: 0px;"><span style="position: absolute; clip: rect(1.828em, 1000em, 2.49em, -0.496em); top: -2.309em; left: 0em;"><span class="mi" id="MathJax-Span-5817" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">w</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; top: -2.4em; left: 0.507em;"><span class="mo" id="MathJax-Span-5818" style="font-size: 50%; font-family: STIXVariants;">′</span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span><span class="mo" id="MathJax-Span-5819" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">∈</span><span class="mi" id="MathJax-Span-5820" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">V<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mi" id="MathJax-Span-5821" style="font-family: STIXGeneral-Regular; padding-left: 0.188em;">exp</span><span class="mo" id="MathJax-Span-5822"></span><span class="mo" id="MathJax-Span-5823" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-5824"><span style="display: inline-block; position: relative; width: 1.31em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5825" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -3.848em; left: 0.45em;"><span class="texatom" id="MathJax-Span-5826"><span class="mrow" id="MathJax-Span-5827"><span class="msup" id="MathJax-Span-5828"><span style="display: inline-block; position: relative; width: 0.785em; height: 0px;"><span style="position: absolute; clip: rect(1.828em, 1000em, 2.49em, -0.496em); top: -2.309em; left: 0em;"><span class="mi" id="MathJax-Span-5829" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">w</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; top: -2.4em; left: 0.507em;"><span class="mo" id="MathJax-Span-5830" style="font-size: 50%; font-family: STIXVariants;">′</span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span><span class="texatom" id="MathJax-Span-5831"><span class="mrow" id="MathJax-Span-5832"><span class="mo" id="MathJax-Span-5833" style="font-family: STIXGeneral-Regular;">/</span></span></span><span class="mi" id="MathJax-Span-5834" style="font-family: STIXGeneral-Italic;">τ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.016em;"></span></span><span class="mo" id="MathJax-Span-5835" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; clip: rect(0.831em, 1000em, 1.239em, -0.507em); top: -1.29em; left: 0em;"><span style="border-left-width: 7.327em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0em;"></span><span style="display: inline-block; width: 0px; height: 1.07em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 2.823em; vertical-align: -1.236em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-162">P_t(w) =\frac{\exp(s_w / \tau)}{\sum_{w' \in V} \exp(s_{w'}/\tau )}</script><p></p>
<p>Raising the temperature <span class="MathJax" id="MathJax-Element-161-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-5786" style="width: 0.516em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.45em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.937em, 1000em, 2.714em, -0.495em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5787"><span class="mi" id="MathJax-Span-5788" style="font-family: STIXGeneral-Italic;">τ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.016em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.612em; vertical-align: -0.075em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-161">\tau</script>: The softmax probabilities becomes more uniform. Thus you get more diverse output. If you lower the temperature, things which are high prob become even more high prob. Note that <span class="MathJax" id="MathJax-Element-163-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-5836" style="width: 2.578em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.309em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.689em, 1000em, 2.727em, -0.495em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5837"><span class="mi" id="MathJax-Span-5838" style="font-family: STIXGeneral-Italic;">τ<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.016em;"></span></span><span class="mo" id="MathJax-Span-5839" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">&lt;</span><span class="mn" id="MathJax-Span-5840" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">1</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.902em; vertical-align: -0.089em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-163">\tau < 1</script> is permissable.</p>
<p>("Mmemonic: If you raise the temp the distribution melts and smoothes, if you lower the temp, the distribution becomes cold and spiky")</p>
</div><div class="cell text-cell"><b>Summary of NLG Tasks and Neural Approaches</b><div><b style="font-size: 14px;"><br></b></div><div><b style="font-size: 14px;">Summarization</b></div><div style="font-size: 14px;">Task: Given input text x, write a summary y which is shorter and contains the main information of x.</div><div style="font-size: 14px;">Summarization can be single-document or multi-document.</div><div><ul><li><span style="font-size: 14px;">Single-document means we write a summary <i>y</i> of a single document <i>x</i>.</span></li><li><span style="font-size: 14px;">Multi-document means we write a summary </span><i style="font-size: 14px;">y</i><span style="font-size: 14px;">&nbsp;of multiple documents <i>x1,…,xn</i>. Typically these documents have overlapping content.&nbsp;</span></li></ul><div><span style="font-size: 14px;">WIthin single-document summarization, there are datasets with source documetns of different lengths and styles:</span></div></div><div><span style="font-size: 14px;">&nbsp; - Gigaword: Task: first two sentences of a news article -&gt; headline. (aka sentence compression)</span></div><div><span style="font-size: 14px;">&nbsp;- LCSTS (Chinese Microblogging): Paragraph -&gt; Sentence Summary</span></div><div><span style="font-size: 14px;">&nbsp; - NYT/CNN/DailyMail: News Article -&gt; (multi)sentence summary</span></div><div><span style="font-size: 14px;"><br></span></div><div><span style="font-size: 14px;">Sentence simplifcation is a different but related task: Rewrite the source text in a simpler (sometimes shorter) way.</span></div><div><span style="font-size: 14px;">&nbsp; - Simple Wikipedia: standard Wikipedia sentence-&gt; simple version</span></div><div><span style="font-size: 14px;">&nbsp; - Newsela: News article -&gt; version written for children</span></div><div><span style="font-size: 14px;"><br></span></div><div><span style="font-size: 14px;">Two main strategies for&nbsp;summarisation:</span></div><div><span style="font-size: 14px;">&nbsp; - <b>Extractive&nbsp;summarisation</b>: Select parts (typically sentences) of the original text to form a summary.</span></div><div><span style="font-size: 14px;">&nbsp;- <b>Abstractive sumamrization</b>: Generate new text using NLP generation techniques. More difficult, more flexibe (more human).</span></div><div><span style="font-size: 14px;"><br></span></div><div><span style="font-size: 14px;"><b>Pre-neural summarization</b>:</span></div><div><span style="font-size: 14px;">Pre-neural summarization systems were mostly extractive. They typically had a pipeline as follows:</span></div><div><ul><li><span style="font-size: 14px;">&nbsp; Content selection: choose some sentences to include</span><br></li><ul><li><span style="font-size: 14px;">Used sentence scoring function based on features, topic keywords, tfidf, also location in the document</span></li><li><span style="font-size: 14px;">Graph based algo&nbsp;</span></li></ul><li><span style="font-size: 14px;">Information ordering: Choose an ordering of those sentences</span><br></li><li><span style="font-size: 14px;">Sentence realization: Edit the sequence of sentences (simplify, remove parts, fix continuity issues).</span><br></li></ul></div><div><span style="font-size: 14px;"><b>ROUGE: Main metric for summarization</b></span></div><div><span style="font-size: 14px;">Like BLEU, it’s based on n-gram overlap, but iwthout brevity penalty, and ROUGE is based on recall while BLEU is based on precision. (Precision is more important for machine translation, but recall is more important for summarization).</span></div><div><span style="font-size: 14px;">However (confusingly) often an F1 version of ROUGE is reported anyway.</span></div><div><span style="font-size: 14px;"><br></span></div><div><span style="font-size: 14px;">ROUGE computation:</span></div><div><span style="font-size: 14px;">ROUGE scores are repoted separaly for each n-gram. The most commonly reported ROUGE scores are ROUGE-1, ROUGE-2, and ROUGE-L: longest common subsequence overlap.&nbsp;</span></div><div><span style="font-size: 14px;"><br></span></div><div><img src="resources/ECB9BEBB7C7FB9AEAE00DE18DB84B1D3.png" alt="Screenshot 2020-01-30 at 4.18.30 PM.png" width="613" height="426"><span style="font-size: 14px;"><br></span></div><div><span style="font-size: 14px;"><br></span></div><div><span style="font-size: 14px;"><b>Neural Approaches to Summarization</b></span></div><div><span style="font-size: 14px;">2015: Rush et al publish the first saeq2seq summarization paper.&nbsp;</span><span style="font-size: 14px;">Single document abstractive sumamrization is a translation task! So standard seq2seq+attention NMT was used.</span></div><div><br></div><div><span style="font-size: 14px;">Other ideas</span></div><div><span style="font-size: 14px;">&nbsp;1. Make it easier to copy. But don’t copy too much!</span></div><div><span style="font-size: 14px;">&nbsp;- Hierarchical / multi-level attention</span></div><div><span style="font-size: 14px;">&nbsp; - More global / high-level content selection</span></div><div><span style="font-size: 14px;">&nbsp; - Use reinforcement learning to directly maximize ROUGE, or other discreate goals (e.g. length)</span></div><div><span style="font-size: 14px;">&nbsp; - Resurrecting pre-neural ideas such as graph algorithms for content selection adn putting them into neural systems.</span></div><div><br></div><div style="font-size: 16px;"><b>Copying Mechanisms:</b></div><div style="font-size: 15px;">Seq2seq + attention systems are good at writing fluent output, but are bad at copying over details (like rare words) correctly.&nbsp;</div><div style="font-size: 15px;">Copy mechanisms use attention to enable a seq2seq system to easily copy words and phrases from the input to the output.</div><div style="font-size: 15px;">&nbsp; - Clearly very useful for summarization</div><div style="font-size: 15px;">&nbsp; - Allowing both copying and generating gives us a hybrid extractive/abstractive approach.</div><div style="font-size: 15px;">&nbsp;- Basically use attention to attend to the thing to copy</div><div style="font-size: 15px;"><br></div><div style="font-size: 15px;">Several papers proposing copy mechanism variants:</div><div style="font-size: 15px;">&nbsp; - Language as a Latent Variable, Miao et al 2016</div><div style="font-size: 15px;">&nbsp; - Abstractive Text Summarization using Sequence-to-Sequence … Nallapati et al 2016</div><div style="font-size: 15px;">&nbsp;- Incorporating Copying Mechanism in Sequence-to-Sequence Learning, Gu et al 2016.</div><div style="font-size: 15px;"><img src="resources/71B588D65A46FC575500ABC635C58369.png" alt="Screenshot 2020-02-16 at 1.58.48 PM.png" width="617" height="461"><br></div><div style="font-size: 15px;">&nbsp;Problems with copying mechanism: They copy too much, and so what should be an abstractive system collapses to a mostly extractive system.</div><div style="font-size: 15px;">Also: They’re bad at overall content selection, especially if the input document is long.&nbsp;</div><div style="font-size: 15px;"><br></div><div style="font-size: 15px;"><b>Bottom up Summarization</b></div><div style="font-size: 15px;">Recall: Pre-neural summarization had separate stages for content selection and text generation. In seq2seq attention summarization, these two stages are mixed together.&nbsp;<span style="font-size: 13px;">On each step of the decoder, we do word-level content selection (attention). This is bad: no global content selection strategy.&nbsp;</span><span style="font-size: 13px;">Bottom Up Summarization as a way to solve this.</span></div><div style="font-size: 15px;"><span style="font-size: 13px;"><br></span></div><div style="font-size: 15px;"><span style="font-size: 13px;">Bottom Up Summarization:&nbsp;</span></div><div>Two stages:</div><div><b>Content selection stage</b>: Use a neural sequence-tagging model to tag words as <i>include</i> or <i>don’t-include</i></div><div><b>Bottom-up attention stage</b>: The seq2seq+attention system can’t attend to words tagged<i> don’t-include </i>(apply a mask)</div><div><br></div><div>Bottom up Summarization is simple but effective!</div><div>&nbsp; - Better overall content selection strategy</div><div>&nbsp; - Less copying of long sequences (i.e. more abstractive output)</div><div><br></div><div><b>Neural Summarization via Reinforcement Learning to directly maximize ROUGE-L</b></div><div>Interesting finding: Using RL instead of ML achieve higher ROUGE scores, but lower human judgement scores - “barely readable summaries”.</div><div>However, a combined objective which is a mix of old fashioned langage model (optimizing for perplexity), and optimizing directly for ROUGE gets better human judgement scores than just the old fashioned langauge model alone.&nbsp;</div><div><br></div><div><br></div><div style="font-size: 17px;"><b>Dialogue Systems</b></div><div><b>Task-oriented Dialogue</b><br></div><div>&nbsp; - Assistive (Customer Service, QA etc)</div><div>&nbsp; - Cooperative (two agents solve a task together through dialogue)</div><div>&nbsp; - Adversarial (two agents content a task through dialogue)</div><div><br></div><div><b>Social Dialogue</b></div><div>&nbsp; - Chit-chat dialogue</div><div><br></div><div>Pre-DL, the difficulty of open-ended freeform NLG, pre-neural dialgoue systems usually used predefined templates.</div><div>As in summarization research, since 2015 there have been many papers applying seq2seq to dialogue.</div><div>Esp:&nbsp;</div><div><b>A Neural Conversational Model</b>, Vinyals et al 2015,&nbsp;</div><div><b>Neural Responding Machine for Short-Text Conversation</b>, Shang et al 2015.</div><div><br></div><div>It quickly became apparent that a naive application of standard seq2seq attention had pervasive deficienceies for chitchat dialogue</div><div>&nbsp; - Genericness</div><div>&nbsp; - Irrelevancy</div><div>&nbsp;- &nbsp;Repetition</div><div>&nbsp; - Not remembering conversation history.</div><div>&nbsp; - Lack of consistent persona</div><div><br></div><div><b>Irrelevant Response problem</b></div><div>Problem: seq2seq often generates response that’s unrelated to user’s utterance, wither becasie it’s generic (“I don’t know), or because changing the subject to somethign unrelated.</div><div><br></div><div>One solution: Optimize for <b>Maximum Mutual Information (MMI) </b>between input S and response T:</div><div>If T is high likelihood anyways it will get penalised, as follows:</div><div></div></div><div class="cell markdown-cell"><p></p><div class="MathJax_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax" id="MathJax-Element-164-Frame" style=""><nobr><span class="math" id="MathJax-Span-5841" style="width: 6.016em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.405em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.003em, 1000em, 3.594em, -0.488em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5842"><span class="mi" id="MathJax-Span-5843" style="font-family: STIXGeneral-Regular;">log</span><span class="mo" id="MathJax-Span-5844"></span><span class="mfrac" id="MathJax-Span-5845" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 3.667em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(1.689em, 1000em, 2.908em, -0.582em); top: -3.22em; left: 50%; margin-left: -1.408em;"><span class="mrow" id="MathJax-Span-5846"><span class="mi" id="MathJax-Span-5847" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-5848" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-5849" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.008em;"></span></span><span class="mo" id="MathJax-Span-5850" style="font-family: STIXGeneral-Regular;">,</span><span class="mi" id="MathJax-Span-5851" style="font-family: STIXGeneral-Italic; padding-left: 0.188em;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.077em;"></span></span><span class="mo" id="MathJax-Span-5852" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; clip: rect(1.689em, 1000em, 2.908em, -0.582em); top: -1.848em; left: 50%; margin-left: -1.774em;"><span class="mrow" id="MathJax-Span-5853"><span class="mi" id="MathJax-Span-5854" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-5855" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-5856" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.008em;"></span></span><span class="mo" id="MathJax-Span-5857" style="font-family: STIXGeneral-Regular;">)</span><span class="mi" id="MathJax-Span-5858" style="font-family: STIXGeneral-Italic;">p</span><span class="mo" id="MathJax-Span-5859" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-5860" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.077em;"></span></span><span class="mo" id="MathJax-Span-5861" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; clip: rect(0.831em, 1000em, 1.239em, -0.507em); top: -1.29em; left: 0em;"><span style="border-left-width: 3.667em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0em;"></span><span style="display: inline-block; width: 0px; height: 1.07em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 2.626em; vertical-align: -1.051em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-164">\log \frac{p(S,T)}{p(S)p(T)}</script><p></p>
<p></p><div class="MathJax_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax" id="MathJax-Element-165-Frame" style=""><nobr><span class="math" id="MathJax-Span-5862" style="width: 16.391em; display: inline-block;"><span style="display: inline-block; position: relative; width: 14.752em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.404em, 1000em, 3.488em, -0.635em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-5863"><span class="texatom" id="MathJax-Span-5864"><span class="mrow" id="MathJax-Span-5865"><span class="munderover" id="MathJax-Span-5866"><span style="display: inline-block; position: relative; width: 0.676em; height: 0px;"><span style="position: absolute; clip: rect(1.712em, 1000em, 2.703em, -0.448em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-5867" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.077em;"></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -4.285em; left: 0.257em;"><span style="height: 0em; vertical-align: 0em; width: 0.386em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-5868" style="font-family: STIXGeneral-Regular; margin-left: -0.386em;">̂&nbsp;<span style="height: 0em; vertical-align: 0em; margin-left: -0.676em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-5869" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">=</span><span class="mi" id="MathJax-Span-5870" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">arg</span><span class="mo" id="MathJax-Span-5871"></span><span class="munderover" id="MathJax-Span-5872" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 1.745em; height: 0px;"><span style="position: absolute; clip: rect(1.905em, 1000em, 2.713em, -0.491em); top: -2.534em; left: 0em;"><span class="mo" id="MathJax-Span-5873" style="font-family: STIXGeneral-Regular;">max</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; clip: rect(1.678em, 1000em, 2.577em, -0.465em); top: -1.624em; left: 0.648em;"><span class="mi" id="MathJax-Span-5874" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.054em;"></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-5875" style="font-family: STIXGeneral-Regular;">{</span><span class="mi" id="MathJax-Span-5876" style="font-family: STIXGeneral-Regular;">log</span><span class="mo" id="MathJax-Span-5877"></span><span class="mi" id="MathJax-Span-5878" style="font-family: STIXGeneral-Italic; padding-left: 0.188em;">p</span><span class="mo" id="MathJax-Span-5879" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-5880" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.077em;"></span></span><span class="texatom" id="MathJax-Span-5881"><span class="mrow" id="MathJax-Span-5882"><span class="mo" id="MathJax-Span-5883" style="font-family: STIXGeneral-Regular;">|</span></span></span><span class="mi" id="MathJax-Span-5884" style="font-family: STIXGeneral-Italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.008em;"></span></span><span class="mo" id="MathJax-Span-5885" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-5886" style="font-family: STIXGeneral-Regular; padding-left: 0.25em;">−</span><span class="mi" id="MathJax-Span-5887" style="font-family: STIXGeneral-Regular; padding-left: 0.25em;">log</span><span class="mo" id="MathJax-Span-5888"></span><span class="mi" id="MathJax-Span-5889" style="font-family: STIXGeneral-Italic; padding-left: 0.188em;">p</span><span class="mo" id="MathJax-Span-5890" style="font-family: STIXGeneral-Regular;">(</span><span class="mi" id="MathJax-Span-5891" style="font-family: STIXGeneral-Italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.077em;"></span></span><span class="mo" id="MathJax-Span-5892" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-5893" style="font-family: STIXGeneral-Regular;">}</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 2.063em; vertical-align: -0.934em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-165">\hat T = \arg \max _T \{ \log p(T|S) - \log p(T) \}</script><p></p>
</div><div class="cell text-cell"><h3>Genericness / boring response problem</h3>
<p>Easy test-time fixes:</p>
<ul>
<li>Directly upweight rare words during beam search.</li>
<li>Use a sampling decoding algo rather than beam search.<br>
Conditioning (training-time) fixes:</li>
<li>Condition the decoder on some additional content (e.g. sample some content words and attend to them).</li>
<li>Train a retrieve and refine model, ratherh than a generate-from-scratch model
<ul>
<li>i.e. sample an utterance from your corpus of human-written utterances, and edit it to fit the current scenario.</li>
<li>A pretty strong method to produce much more diverse and human like and interesting utterances!</li>
</ul>
</li>
</ul>
</div><div class="cell text-cell"><p><b>Repitition Problem:</b><br>
Simple Soution:</p>
<ul>
<li>Directly blcok repeating n-grams during beam search
<ul>
<li>Usually pretty efective!<br>
More complex solutions:</li>
</ul>
</li>
<li>Train a coverage mechanism - in seq2seq, this is an objective that prevents the atention mechanism from attending to the same words multiple times</li>
<li>Define a training objective to discourage repetition
<ul>
<li>However, teacher forcing tends to make this hard, because you are not feeding the output back in the model itself, thus making hte model not differentiable on the output. If this is a non-differentiable function of the generated output, then will need some technique like RL to train.</li>
</ul>
</li>
</ul>
<p><b style="font-size: 19px;">Storytelling</b><br>
Most neural storytelling work uses some kind of prompt</p>
<ul>
<li>Generate a story-like paragraph given an image</li>
<li>Generate a story given a brief writing prompt</li>
<li>Generate the next sentence of a story, given the story so far (story continuation)
<ul>
<li>This is different to the previous two, because we are not concerned with the system's performace over several generated sentences.</li>
</ul>
</li>
</ul>
<p><strong>Generating Stories about Images, Skip-Thought Vectors</strong><br>
Question: How to get around lack of parallel data?<br>
Answer: Use a common sentence-encoding space.</p>
<ul>
<li>Skip-throught vectors are a type of general-purpose sentence embedding method.
<ul>
<li>The idea is similar to how we learn an embedding for a word by trying to predict the words around it.</li>
</ul>
</li>
<li>Using COCO (an image captioning dataset), learn a mapping from images to the skip-thought encodings of their captions.</li>
<li>Using the target style corpus (Taylor Swift Lyrics), train a RNN-LM to decode a skip-thought vector to the original text</li>
<li>Put the two together.<br>
<strong>Could be a good personal project to replicate!</strong></li>
</ul>  
<div><br></div><div style="font-size: 16px;"><b>Automatic Evaluation Metrics for NLG</b></div><div style="font-size: 14px;">Word-overlap based metrics: BLEU, ROUGE, METEOR, F1 etc are not ideal for translation, even worse for summarization, and even worse for dialogue, which is more open-ended than summarizaiton.&nbsp;</div><div style="font-size: 14px;"><br></div><div style="font-size: 14px;">Word voerlap metrics are not a good fit for dialogue. Very little correlation between BLUE and human score.</div><div style="font-size: 14px;"><br></div><div style="font-size: 14px;">Perplexity tells you how strong your langauge model is, but doesn’t tell you anything about generation (if your decoding algo is bad, perplexity is unaffected).</div><div style="font-size: 14px;">Word embedding based metrics to capture the similarity of the word embeddings - unfortuantely, does not correlate well with human jusgements for open-ended tasks liek dialogiue.&nbsp;</div><div style="font-size: 14px;"><br></div><div style="font-size: 14px;">Generally, we define more focused automatic metrics to capture particular aspects of generated text:</div><div>&nbsp; - Fluency - Take a language model trained on text and generate probability with respect to that that language model.</div><div>&nbsp; - Correct stule - get probability with respect to a Langauge Model trained on target corpus</div><div>&nbsp; - Diversity - rare word usage, uniqueness of n-grams</div><div>&nbsp; - Relevance to input (semantic similarity measures)</div><div>&nbsp; - Simple thigns like length and repetition</div><div>&nbsp; - Task-specific metrics, e.g. compression rate for summarization</div><div><br></div><div>Though these don’t measure overall quality, they can help us track some important qualities that we care about.</div><div><br></div><div><b>Human Evaluation</b></div><div>Human jusgements are regarded as the gold standard, but are slow and expensive. But also,</div><div>Humans are inconsistent, can be illogical, lost concentration, misinterpret your question, etc</div><div><br></div><div><br></div><div><img src="resources/75F603CBADE36E27FB84D93E30CE5ECB.png" alt="Screenshot 2020-02-16 at 2.45.03 PM.png" width="612" height="454"><br></div><div><img src="resources/204AFB122B3DCA81861702F59E39FAAE.png" alt="Screenshot 2020-02-16 at 2.46.39 PM.png" width="619" height="450"><br></div><div><br></div><div><div><b>Appendix 1:</b></div><div><img src="resources/8B63E1330A3432DD5E29E1D9F8D9D7E7.png" alt="Screenshot 2020-02-16 at 2.32.17 PM.png" width="465" height="204"><br></div><div><br></div>
</div><div class="cell text-cell">&nbsp; -&nbsp;</div></div>

    </body>
    </html>
  