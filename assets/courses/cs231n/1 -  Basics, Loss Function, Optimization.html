
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <!-- common.css -->
      <style>* {-webkit-tap-highlight-color: rgba(0,0,0,0);}html {-webkit-text-size-adjust: none;}body {font-family: -apple-system, Helvetica, Arial, sans-serif;margin: 0;padding: 20px;color: #333;word-wrap: break-word;}h1, h2, h3, h4, h5, h6 {line-height: 1.1;}img {max-width: 100% !important;height: auto;}blockquote {margin: 0;padding: 0 15px;color: #777;border-left: 4px solid #ddd;}hr {background-color: #ddd;border: 0;height: 1px;margin: 15px 0;}code {font-family: Menlo, Consolas, 'Ubuntu Mono', Monaco, 'source-code-pro', monospace;line-height: 1.4;margin: 0;padding: 0.2em 0;font-size: 90%;background-color: rgba(0,0,0,0.04);border-radius: 3px;}pre > code {margin: 0;padding: 0;font-size: 100%;word-break: normal;background: transparent;border: 0;}ol {list-style-type: decimal;}ol ol, ul ol {list-style-type: lower-latin;}ol ol ol, ul ol ol, ul ul ol, ol ul ol {list-style-type: lower-roman;}table {border-spacing: 0;border-collapse: collapse;margin-top: 0;margin-bottom: 16px;}table th {font-weight: bold;}table th, table td {padding: 6px 13px;border: 1px solid #ddd;}table tr {border-top: 1px solid #ccc;}table tr:nth-child(even) {background-color: #f8f8f8;}input[type="checkbox"] {cursor: default;margin-right: 0.5em;font-size: 13px;}.task-list-item {list-style-type: none;}.task-list-item+.task-list-item {margin-top: 3px;}.task-list-item input {float: left;margin: 0.3em 1em 0.25em -1.6em;vertical-align: middle;}#tag-field {margin: 8px 2px 10px;}#tag-field .tag {display: inline-block;background: #cadff3;border-radius: 4px;padding: 1px 8px;color: black;font-size: 12px;margin-right: 10px;line-height: 1.4;}</style>
      <!-- ace-static.css -->
      <style>.ace_static_highlight {white-space: pre-wrap;}.ace_static_highlight .ace_gutter {width: 2em;text-align: right;padding: 0 3px 0 0;margin-right: 3px;}.ace_static_highlight.ace_show_gutter > .ace_line {padding-left: 2.6em;}.ace_static_highlight .ace_line {position: relative;}.ace_static_highlight .ace_gutter-cell {-moz-user-select: -moz-none;-khtml-user-select: none;-webkit-user-select: none;user-select: none;top: 0;bottom: 0;left: 0;position: absolute;}.ace_static_highlight .ace_gutter-cell:before {content: counter(ace_line, decimal);counter-increment: ace_line;}.ace_static_highlight {counter-reset: ace_line;}</style>
      <style>.ace-chrome .ace_gutter {background: #ebebeb;color: #333;overflow : hidden;}.ace-chrome .ace_print-margin {width: 1px;background: #e8e8e8;}.ace-chrome {background-color: #FFFFFF;color: black;}.ace-chrome .ace_cursor {color: black;}.ace-chrome .ace_invisible {color: rgb(191, 191, 191);}.ace-chrome .ace_constant.ace_buildin {color: rgb(88, 72, 246);}.ace-chrome .ace_constant.ace_language {color: rgb(88, 92, 246);}.ace-chrome .ace_constant.ace_library {color: rgb(6, 150, 14);}.ace-chrome .ace_invalid {background-color: rgb(153, 0, 0);color: white;}.ace-chrome .ace_fold {}.ace-chrome .ace_support.ace_function {color: rgb(60, 76, 114);}.ace-chrome .ace_support.ace_constant {color: rgb(6, 150, 14);}.ace-chrome .ace_support.ace_type,.ace-chrome .ace_support.ace_class.ace-chrome .ace_support.ace_other {color: rgb(109, 121, 222);}.ace-chrome .ace_variable.ace_parameter {font-style:italic;color:#FD971F;}.ace-chrome .ace_keyword.ace_operator {color: rgb(104, 118, 135);}.ace-chrome .ace_comment {color: #236e24;}.ace-chrome .ace_comment.ace_doc {color: #236e24;}.ace-chrome .ace_comment.ace_doc.ace_tag {color: #236e24;}.ace-chrome .ace_constant.ace_numeric {color: rgb(0, 0, 205);}.ace-chrome .ace_variable {color: rgb(49, 132, 149);}.ace-chrome .ace_xml-pe {color: rgb(104, 104, 91);}.ace-chrome .ace_entity.ace_name.ace_function {color: #0000A2;}.ace-chrome .ace_heading {color: rgb(12, 7, 255);}.ace-chrome .ace_list {color:rgb(185, 6, 144);}.ace-chrome .ace_marker-layer .ace_selection {background: rgb(181, 213, 255);}.ace-chrome .ace_marker-layer .ace_step {background: rgb(252, 255, 0);}.ace-chrome .ace_marker-layer .ace_stack {background: rgb(164, 229, 101);}.ace-chrome .ace_marker-layer .ace_bracket {margin: -1px 0 0 -1px;border: 1px solid rgb(192, 192, 192);}.ace-chrome .ace_marker-layer .ace_active-line {background: rgba(0, 0, 0, 0.07);}.ace-chrome .ace_gutter-active-line {background-color : #dcdcdc;}.ace-chrome .ace_marker-layer .ace_selected-word {background: rgb(250, 250, 255);border: 1px solid rgb(200, 200, 250);}.ace-chrome .ace_storage,.ace-chrome .ace_keyword,.ace-chrome .ace_meta.ace_tag {color: rgb(147, 15, 128);}.ace-chrome .ace_string.ace_regex {color: rgb(255, 0, 0)}.ace-chrome .ace_string {color: #1A1AA6;}.ace-chrome .ace_entity.ace_other.ace_attribute-name {color: #994409;}.ace-chrome .ace_indent-guide {background: url("data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAACCAYAAACZgbYnAAAAE0lEQVQImWP4////f4bLly//BwAmVgd1/w11/gAAAABJRU5ErkJggg==") right repeat-y;}</style>
      <!-- export.css -->
      <style>
        body{margin:0 auto;max-width:800px;line-height:1.4}
        #nav{margin:5px 0 10px;font-size:15px}
        #titlearea{border-bottom:1px solid #ccc;font-size:17px;padding:10px 0;}
        #contentarea{font-size:15px;margin:16px 0}
        .cell{outline:0;min-height:20px;margin:5px 0;padding:5px 0;}
        .code-cell{font-family:Menlo,Consolas,'Ubuntu Mono',Monaco,'source-code-pro',monospace;font-size:12px;}
        .latex-cell{white-space:pre-wrap;}
      </style>
      <!-- User CSS -->
      <style> .text-cell {font-size: 15px;}.code-cell {font-size: 12px;}.markdown-cell {font-size: 15px;}.latex-cell {font-size: 15px;}</style>
    </head>
    <body>
      <div id="titlearea">
        <h2>CS231N - Lecture 1/2/3: Computer Vision Intro, Basics, Loss Functions and Optimization, Old Fashioned Image Features</h2>
      </div>
      <div id="contentarea"><div class="cell text-cell"><div style="font-size: 18px;"><b>Computer Vision Intro</b></div><div><b>History of Computer Vision</b></div>The onset of vision started the Cambrian Evolution.&nbsp;<div>In Humans, 50% of our neurons are involved in visual processing.</div><div><br></div><div>Hubel and Weisel - Cat visual neocortex.</div><div>Block World - first Vision paper</div><div>1966 - The Summer Vision Project</div><div>David Marr - MIT vision scientist, wrote book &lt;Vision&gt;</div><div>Generalized Cylinder, Pictoral Structure</div><div><br></div><div>Object segmentation (Normalized Cut 1997)</div><div>Face Detection (Viola and Jones)</div><div>SIFT Features (Lowe, 1999)</div><div>1998 - LeCun et al 1998. First CNN paper for recognizing digits<br></div><div>Spatial Pyramid Matching (2006)</div><div>Human Gesture Recognition (Histogram of Gradients HoG 2005, Deformable Part Model 2009)</div><div><br></div><div><b>Old Fashioned Image Features</b></div><div>Color Histogram - have a huge spectrum of color buckets and for each pixel, map the pixel into the bucket to get a histogram of colors (Appendix 6)</div><div>Histogram of Oriented Gradients (HoG) - divide image into 8x8 pixelm regions, within each region quantize edge direction into 9 bins, which is a histogram of occurence of 9 difference types of edges in this 8x8 pixel region (9d vector). Formerly very popularly used for object recognition. &nbsp;(Appendix 6)</div><div>Bag of Words - Extract random patches from images, cluster patches to form “codebook” of visual words”, and encode images of “bags” of these patches. The “words” tend to cover different types of edges. (Appendix 6)</div><div><br></div><div><b>Datasets:</b></div><div>Object Recognition was the blocking problem in Computer Vision (PASCAL Visual Object Challenge, 20 object categories)</div><div>CIFAR 10 (small test set - 10 classes, 50,000 training images, 10000 test images)<br></div><div>ImageNET - Recognize most of the objects in the world (downloaded billions of data off the internet, organized by wordNET, then labeled using Mechanical Turk) - 1000 classes, 1.4 million images (2)</div><div><br></div><div><b>CV Problems</b></div><div>Image Classification&nbsp;</div><div>Object Detection</div><div>Action Classification</div><div>Image captioning</div><div>Sementic Segmentation</div><div>AR/VR</div><div><br></div><div><b>Naive Baselines</b></div><div><div>&nbsp; - Toy Naive Baseline: k- Nearest Neighbors with L1 distance - Never used in practice because pixel distance between images is not semantically important, and because of the curse of dimensionality (Appendix 1)</div><div>&nbsp; - Toy Naive Baseline: Linear Classification</div></div><div><br></div><div><b>Loss Functions and Optimization:</b><br></div><div>In classification generally these two types are used:</div><div>SVM Loss (Appendix 4)</div><div>Softmax loss (Appendix 4)</div><div>You also have to do regularization (Appendix 5)</div><div><div><br></div><div><b><br></b></div><div><b>Appendix 1:</b><br></div><div>L1 metric for k-Nearest Neighbors</div><div><img src="resources/6F223AC67DC8F51127DCB432E3DA5EDC.png" alt="Screenshot 2020-02-23 at 10.44.10 PM.png" width="820" height="388"><br></div><div>L1 distance depends on the coordinate system (so if each feature has a defined distance, maybe L1 is best)</div><div>You can also use L2 distance.&nbsp;</div><div><br></div><div><b>K-Nearest Neighbors</b>: Increasing k smoothes your decision boundary. Classification based on majority vote between k nearest neighbors.</div><div><img src="resources/9E7233F4094C31FA3008565E1A27BEC7.png" alt="Screenshot 2020-02-23 at 10.47.16 PM.png" width="832" height="381"></div></div><div><br></div><div style="font-size: 15px;"><b>Appendix 2: State of the Art on ImageNet</b></div><div style="font-size: 15px;"><img src="resources/ABBC2081A80BB76E4AB4BA8C71EF72B3.png" alt="Screenshot 2020-02-23 at 10.11.10 PM.png" width="827" height="421"><b><br></b></div><div style="font-size: 15px;"><b><br></b></div><div><img src="resources/3C0CD18124519890E9B58F88F528C7E5.png" alt="Screenshot 2020-02-23 at 10.09.45 PM.png" width="1170" height="452"><br></div><div><br></div><div><img src="resources/051EAFD94A97DB7D28EFF6DA7C2C64BB.png" alt="Screenshot 2020-02-23 at 10.08.31 PM.png" width="877" height="420"><br></div><div><a href="https://paperswithcode.com/sota/image-classification-on-imagenet">https://paperswithcode.com/sota/image-classification-on-imagenet</a><br></div><div><br></div><div><b>Appendix 3:</b></div><div>Image Retrieval Using Scene Graphs</div><div><img src="resources/785C8DCEF2B650CB354846163EFDE442.png" alt="Screenshot 2020-02-23 at 10.14.35 PM.png" width="830" height="423"><br></div><div><br></div><div>Appendix 4: SVM Loss</div><div><img src="resources/32510388F73AE313CC206B91D627F169.png" alt="Screenshot 2020-02-24 at 10.40.47 AM.png" width="824" height="430"><br></div><div><img src="resources/22FD4F9EF664C8316532450F4740B297.png" alt="Screenshot 2020-02-24 at 10.44.32 AM.png" width="769" height="395"><br></div><div><img src="resources/E749F00F3C84BD9E074747DBE7280AB4.png" alt="Screenshot 2020-02-24 at 11.13.54 AM.png" width="830" height="416"><br></div><div><img src="resources/1F37A5E6852F9ACFE15D9615B51303C2.png" alt="Screenshot 2020-02-24 at 11.16.17 AM.png" width="830" height="417"><img src="resources/D2ACD583F4C569698C1A88530E707441.png" alt="Screenshot 2020-02-24 at 11.39.00 AM.png" width="829" height="429"><br></div><div><br></div><div><b>Appendix 5: Regularization</b></div><div><img src="resources/56524F105C46B44ACA5012AEAE445ADA.png" alt="Screenshot 2020-02-24 at 10.55.59 AM.png" width="826" height="433"><b><br></b></div><div><img src="resources/8359A90CE4E036773EB8F82E52A596D5.png" alt="Screenshot 2020-02-24 at 11.03.51 AM.png" width="812" height="408"><br></div><div><br></div><div><b>Appendix 6</b>: <b>Old Fashioned Image Features</b></div><div><img src="resources/2FE5C321A0FE669231AE6114F5B9B314.png" alt="Screenshot 2020-02-24 at 2.45.54 PM.png" width="807" height="406"><br></div><div><img src="resources/7AFC2288AB93B7A8A177559013FB797A.png" alt="Screenshot 2020-02-24 at 2.46.13 PM.png" width="781" height="403"><br></div><div><img src="resources/1C4037E568DC9DBEC39F596F7BB49156.png" alt="Screenshot 2020-02-24 at 2.51.08 PM.png" width="816" height="415"><br></div></div></div>
    </body>
    </html>
  