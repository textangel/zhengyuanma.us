      <div id="titlearea">
        <h2>A History of Neural Machine Translation</h2>
      </div>
      <div id="contentarea"><div class="cell markdown-cell"><p>Neural Machine Translation (NLP) is one of the most paradigmatic applications of neural networks to Natural Language Processing (NLP). The history of the field has been dominated by statistical approaches and the LSTM recurrent neural network, but currently is dominated primiarily by the Transformer architecture.</p>
<h3>The Foundations of Neural Nachine Translation</h3>
<p>Neural networks have been worked on since the early 1960s. [1] In much early work it was hypothesized that a single neural network layer repeatedly applied to different input at different "time-steps", the <strong>recurrent neural network</strong>, would be useful in predicting sequential data. Ronald Williams and David Zipster produced the canonical learning algorithm for the RNN, <strong>backpropagation through time</strong>, in 1992. [2] RNNs trained using back-propagation-through-time had a critical liability: to train them required pushing back the dependency on the current input many time-steps, but after many time-steps the gradient tends to shrink rapidly to zero. For this reason, RNNs cannot learn long-term dependencies. In 1997, Hochreiter and Schmidhuber proposed <strong>Long Short Term Memory (LSTM)</strong> networks, a variant of the RNN with input, output, and forget gates which controlled the gradient flow and greatly increased the sequence dependency length that can be learned. [3] For this reason, LSTMs were the dominant paradigm in Natural Langauge Processing until 2018.</p>
<p style="text-align: center;"><img src="./assets/projects/nmt/resources/5E5670652F59B2A8C543A1E4B22A66B0.jpg" alt="Structure-of-the-LSTM-cell-and-equations-that-describe-the-gates-of-an-LSTM-cell.jpg" width="300"></p>
<h3>Language Modeling and The Neural Turn</h3>
<p><strong>Language modeling</strong> is the foundational task for Machine Translation. A language model seeks to determine the probability that a particular segment of text is natural langauge. Languages models can be used to generate text, usually by generating the text word as the word which, if appended to the current sentence, would maximize the probability that the text is natural langauge. Historically, langauges were modeled using statistical techniques on <span class="MathJax" id="MathJax-Element-20-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-247" style="width: 0.578em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.507em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.712em, -0.493em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-248"><span class="mi" id="MathJax-Span-249" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.625em; vertical-align: -0.072em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-20">n</script>-gram (unique consecutive <span class="MathJax" id="MathJax-Element-20-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-247" style="width: 0.578em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.507em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.712em, -0.493em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-248"><span class="mi" id="MathJax-Span-249" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.625em; vertical-align: -0.072em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-20">n</script>-word chunks) counts in a text corpus, typically incorporating some type of smoothing such as Kneser-Ney Smoothing to correct for low-frequency words. [4] (Image 1)</p>
<p>In 2003, Yoshua Bengio et al. introduced the first successful application of neural networks to language modeling. [5] This model was a simple feedforward neural network that looks back <span class="MathJax" id="MathJax-Element-20-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-247" style="width: 0.578em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.507em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.712em, -0.493em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-248"><span class="mi" id="MathJax-Span-249" style="font-family: STIXGeneral-Italic;">n</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.625em; vertical-align: -0.072em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-20">n</script> words and computes the probability of the next word, according to the objective function<br>
</p><div class="MathJax_Display" role="textbox" aria-readonly="true" style="text-align: center;"><span class="MathJax" id="MathJax-Element-21-Frame" style=""><nobr><span class="math" id="MathJax-Span-250" style="width: 24.266em; display: inline-block;"><span style="display: inline-block; position: relative; width: 21.847em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.474em, 1000em, 2.91em, -0.823em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-251"><span class="texatom" id="MathJax-Span-252"><span class="mrow" id="MathJax-Span-253"><span class="munderover" id="MathJax-Span-254"><span style="display: inline-block; position: relative; width: 0.45em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.909em, -0.531em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-255" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -4.073em; left: 0.07em;"><span style="height: 0em; vertical-align: 0em; width: 0.386em; display: inline-block; overflow: hidden;"></span><span class="mo" id="MathJax-Span-256" style="font-family: STIXGeneral-Regular; margin-left: -0.386em;">̂&nbsp;<span style="height: 0em; vertical-align: 0em; margin-left: -0.676em;"></span></span><span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span><span style="display: inline-block; width: 0px; height: 3.998em;"></span></span></span></span></span></span><span class="mo" id="MathJax-Span-257" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">=</span><span class="mi" id="MathJax-Span-258" style="font-family: STIXGeneral-Italic; padding-left: 0.313em;">s</span><span class="mi" id="MathJax-Span-259" style="font-family: STIXGeneral-Italic;">o</span><span class="mi" id="MathJax-Span-260" style="font-family: STIXGeneral-Italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.146em;"></span></span><span class="mi" id="MathJax-Span-261" style="font-family: STIXGeneral-Italic;">t<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.018em;"></span></span><span class="mi" id="MathJax-Span-262" style="font-family: STIXGeneral-Italic;">m</span><span class="mi" id="MathJax-Span-263" style="font-family: STIXGeneral-Italic;">a</span><span class="mi" id="MathJax-Span-264" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-265" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-266"><span style="display: inline-block; position: relative; width: 2.005em; height: 0px;"><span style="position: absolute; clip: rect(1.712em, 1000em, 2.721em, -0.436em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-267" style="font-family: STIXGeneral-Italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.073em;"></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.721em; left: 1.029em;"><span class="texatom" id="MathJax-Span-268"><span class="mrow" id="MathJax-Span-269"><span class="mo" id="MathJax-Span-270" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-271" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">2</span><span class="mo" id="MathJax-Span-272" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mi" id="MathJax-Span-273" style="font-family: STIXGeneral-Regular; padding-left: 0.188em;">tanh</span><span class="mo" id="MathJax-Span-274"></span><span class="mo" id="MathJax-Span-275" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-276"><span style="display: inline-block; position: relative; width: 2.005em; height: 0px;"><span style="position: absolute; clip: rect(1.712em, 1000em, 2.721em, -0.436em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-277" style="font-family: STIXGeneral-Italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.073em;"></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.721em; left: 1.029em;"><span class="texatom" id="MathJax-Span-278"><span class="mrow" id="MathJax-Span-279"><span class="mo" id="MathJax-Span-280" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-281" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-282" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mi" id="MathJax-Span-283" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-284" style="font-family: STIXGeneral-Regular; padding-left: 0.25em;">+</span><span class="msubsup" id="MathJax-Span-285" style="padding-left: 0.25em;"><span style="display: inline-block; position: relative; width: 1.483em; height: 0px;"><span style="position: absolute; clip: rect(1.682em, 1000em, 2.714em, -0.484em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-286" style="font-family: STIXGeneral-Italic;">b</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.721em; left: 0.507em;"><span class="texatom" id="MathJax-Span-287"><span class="mrow" id="MathJax-Span-288"><span class="mo" id="MathJax-Span-289" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-290" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span><span class="mo" id="MathJax-Span-291" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-292" style="font-family: STIXGeneral-Regular;">)</span><span class="mo" id="MathJax-Span-293" style="font-family: STIXGeneral-Regular; padding-left: 0.25em;">+</span><span class="msubsup" id="MathJax-Span-294" style="padding-left: 0.25em;"><span style="display: inline-block; position: relative; width: 2.005em; height: 0px;"><span style="position: absolute; clip: rect(1.712em, 1000em, 2.721em, -0.436em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-295" style="font-family: STIXGeneral-Italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.073em;"></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.721em; left: 1.029em;"><span class="texatom" id="MathJax-Span-296"><span class="mrow" id="MathJax-Span-297"><span class="mo" id="MathJax-Span-298" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-299" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span class="mo" id="MathJax-Span-300" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mi" id="MathJax-Span-301" style="font-family: STIXGeneral-Italic;">x<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mo" id="MathJax-Span-302" style="font-family: STIXGeneral-Regular; padding-left: 0.25em;">+</span><span class="msubsup" id="MathJax-Span-303" style="padding-left: 0.25em;"><span style="display: inline-block; position: relative; width: 1.483em; height: 0px;"><span style="position: absolute; clip: rect(1.682em, 1000em, 2.714em, -0.484em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-304" style="font-family: STIXGeneral-Italic;">b</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.721em; left: 0.507em;"><span class="texatom" id="MathJax-Span-305"><span class="mrow" id="MathJax-Span-306"><span class="mo" id="MathJax-Span-307" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="mn" id="MathJax-Span-308" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">3</span><span class="mo" id="MathJax-Span-309" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-310" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.344em; vertical-align: -0.292em;"></span></span></nobr></span></div><script type="math/tex; mode=display" id="MathJax-Element-21">\hat y = softmax (W^{(2)} \tanh(W^{(1)} x+b^{(1)})+W^{(3)} x+b^{(3)})</script><br>
Despite a serious limitation, that their feedforward neural network was unable to look more than a few words back as it required an exponentially increased parameter count with each additional word, this paper was extremely influential in showing that neural networks can produce useful, low-dimensional <strong>word-embeddings</strong>: semantic-rich representations of individual words as points in <span class="MathJax" id="MathJax-Element-22-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-311" style="width: 0.641em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.563em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.682em, 1000em, 2.716em, -0.492em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-312"><span class="mi" id="MathJax-Span-313" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.027em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.898em; vertical-align: -0.077em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-22">d</script> (e.g. 100) dimensional space, which are used in subsequent NLP applications.  (Image 2) Because of the limitations of feedforward networks for language modeling, LSTMs increadingly became used for this purpose.<p></p>
<h3>Translation - Encoder-Decoder</h3>
<p>Inspired by the success of neural networks in image recognition in 2012, Ilya Sutskever, Oriol Vinyals, and Quoc Le pioneered the <strong>encoder-decoder</strong> paradigm for neural machine translation in 2014, which continues to be the dominant paradigm in machine translation to this day. [6] An encoder-decoder architecture performs machine translation using two separate language models, the "encoder" recognizing text in the source langauge (e.g. English) and the "decoder" producing text in the target language (e.g. Spanish). The encoder and decoder, in this case, are both LSTM language models. LSTMs take in input and maintain an internal hidden state which is used to generate output. One can think of the LSTM hidden state as summarizing all the input it has seen so far.</p>
<p>Whereas in a LSTM language model, the last encoder hidden state would be used to produce the the last output (in English),  in Sutskever's encoder-decoder model, the last encoder hidden state is passed to the decoder to be used as the first decoder hidden state. In this way, the decoder is "triggered" by the information already stored in the encoder to produce the translated sentence (in Spanish). In Sutskever's model, the full encoder-decoder architecture is jointly trained end-to-end, that is, using parallel text in both the source and target languages. The source text (in English) is passed through the encoder and is subsequently decoded (into Spanish) by the decoder, which is then matched against the "true" Spanish text to determine how close the translation was. Scoring metrics such as <strong>BLEU</strong> compute how close the generated output sentence is to the actual target sentence.</p>
<p style="text-align: center;"><img src="./assets/projects/nmt/resources/15787FF00858F259634012AE9F410824.png" alt="Screen Shot 2020-09-15 at 8.19.07 PM.png" width="300"></p>
<h3>Translation - Attention</h3>
<p>An architectural innovation which greatly improved the accuracy of LSTM-based translations was the <strong>attention mechanism</strong>, which was pioneered by Bahdanau et al in 2014. [7] Recall that LSTM encoder-decoder translation architectures use the last hidden state of the encoder to pass on information about the input to the decoder. This is rather lossy and inefficient, because it requires all the information in the input sentence (Supposing <span class="MathJax" id="MathJax-Element-23-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-314" style="width: 2.828em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.534em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.677em, 1000em, 2.717em, -0.476em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-315"><span class="mn" id="MathJax-Span-316" style="font-family: STIXGeneral-Regular;">50000</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.904em; vertical-align: -0.078em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-23">50000</script> English words and a sentence length of <span class="MathJax" id="MathJax-Element-24-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-317" style="width: 1.141em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.014em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.689em, 1000em, 2.717em, -0.478em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-318"><span class="mn" id="MathJax-Span-319" style="font-family: STIXGeneral-Regular;">20</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.891em; vertical-align: -0.078em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-24">20</script>, that's <span class="MathJax" id="MathJax-Element-25-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-320" style="width: 3.766em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.378em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.134em, 1000em, 2.379em, -0.476em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-321"><span class="msubsup" id="MathJax-Span-322"><span style="display: inline-block; position: relative; width: 3.341em; height: 0px;"><span style="position: absolute; clip: rect(1.677em, 1000em, 2.717em, -0.476em); top: -2.534em; left: 0em;"><span class="mn" id="MathJax-Span-323" style="font-family: STIXGeneral-Regular;">50000</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.724em; left: 2.534em;"><span class="texatom" id="MathJax-Span-324"><span class="mrow" id="MathJax-Span-325"><span class="mn" id="MathJax-Span-326" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">20</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.132em; vertical-align: -0.078em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-25">50000^{20}</script> distinct possible sentences) to be "squished" into the 100 or so dimensions of the last hidden state. As the decoder generates text based on this representation, it must have all the information perfectly present or the translation will be lacking or even nonsensical. Bahdanau's attention mechianism fixes this by allowing the decoder to "peek" at the entire encoder input at each decoding step, computing at each step a "soft alignment" of the input words which are most relevant to next word to be decoded. Bahdanau achieved this as follows:</p>
<p>A traditional RNN can be parameterized as <span class="MathJax" id="MathJax-Element-26-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-327" style="width: 7.703em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.926em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.687em, 1000em, 2.952em, -0.491em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-328"><span class="msubsup" id="MathJax-Span-329"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-330" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-331" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-332" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">=</span><span class="mi" id="MathJax-Span-333" style="font-family: STIXGeneral-Italic; padding-left: 0.313em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.146em;"></span></span><span class="mo" id="MathJax-Span-334" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-335"><span style="display: inline-block; position: relative; width: 1.652em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-336" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="texatom" id="MathJax-Span-337"><span class="mrow" id="MathJax-Span-338"><span class="mi" id="MathJax-Span-339" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-340" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-341" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-342" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-343" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 1.652em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.909em, -0.531em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-344" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.067em; left: 0.45em;"><span class="texatom" id="MathJax-Span-345"><span class="mrow" id="MathJax-Span-346"><span class="mi" id="MathJax-Span-347" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-348" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-349" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-350" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.154em; vertical-align: -0.339em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-26">s_i=f(s_{i-1},y_{i-1})</script>, where <span class="MathJax" id="MathJax-Element-27-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-351" style="width: 0.891em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.788em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.585em, 1000em, 2.523em, -0.491em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-352"><span class="msubsup" id="MathJax-Span-353"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-354" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-355" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.791em; vertical-align: -0.238em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-27">s_i</script> is the <span class="MathJax" id="MathJax-Element-28-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-356" style="width: 0.391em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.338em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.711em, 1000em, 2.714em, -0.458em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-357"><span class="mi" id="MathJax-Span-358" style="font-family: STIXGeneral-Italic;">i</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.863em; vertical-align: -0.075em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-28">i</script>-th RNN hidden state and <span class="MathJax" id="MathJax-Element-29-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-359" style="width: 0.891em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.788em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.586em, 1000em, 2.614em, -0.531em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-360"><span class="msubsup" id="MathJax-Span-361"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.909em, -0.531em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-362" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.067em; left: 0.45em;"><span class="mi" id="MathJax-Span-363" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.891em; vertical-align: -0.339em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-29">y_i</script> is the <span class="MathJax" id="MathJax-Element-28-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-356" style="width: 0.391em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.338em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.711em, 1000em, 2.714em, -0.458em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-357"><span class="mi" id="MathJax-Span-358" style="font-family: STIXGeneral-Italic;">i</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.863em; vertical-align: -0.075em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-28">i</script>-th input. Bahdanau changed this to <span class="MathJax" id="MathJax-Element-30-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-364" style="width: 9.016em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.108em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.687em, 1000em, 2.952em, -0.491em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-365"><span class="msubsup" id="MathJax-Span-366"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-367" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-368" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-369" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">=</span><span class="mi" id="MathJax-Span-370" style="font-family: STIXGeneral-Italic; padding-left: 0.313em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.146em;"></span></span><span class="mo" id="MathJax-Span-371" style="font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-372"><span style="display: inline-block; position: relative; width: 1.652em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-373" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="texatom" id="MathJax-Span-374"><span class="mrow" id="MathJax-Span-375"><span class="mi" id="MathJax-Span-376" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-377" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-378" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-379" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-380" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 1.652em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.909em, -0.531em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-381" style="font-family: STIXGeneral-Italic;">y</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.067em; left: 0.45em;"><span class="texatom" id="MathJax-Span-382"><span class="mrow" id="MathJax-Span-383"><span class="mi" id="MathJax-Span-384" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-385" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-386" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-387" style="font-family: STIXGeneral-Regular;">,</span><span class="msubsup" id="MathJax-Span-388" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.714em, -0.477em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-389" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-390" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-391" style="font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.154em; vertical-align: -0.339em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-30">s_i=f(s_{i-1},y_{i-1}, c_i)</script>, where <span class="MathJax" id="MathJax-Element-31-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-392" style="width: 0.891em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.788em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.586em, 1000em, 2.523em, -0.477em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-393"><span class="msubsup" id="MathJax-Span-394"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.714em, -0.477em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-395" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-396" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.79em; vertical-align: -0.238em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-31">c_i</script> is the attention output and is determined by how well a particular representation in the source encoding <span class="MathJax" id="MathJax-Element-32-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-397" style="width: 0.953em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.845em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.344em, 1000em, 2.523em, -0.488em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-398"><span class="msubsup" id="MathJax-Span-399"><span style="display: inline-block; position: relative; width: 0.807em; height: 0px;"><span style="position: absolute; clip: rect(1.682em, 1000em, 2.712em, -0.488em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-400" style="font-family: STIXGeneral-Italic;">h</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.507em;"><span class="mi" id="MathJax-Span-401" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.058em; vertical-align: -0.238em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-32">h_i</script> aligns with the current decoder hidden state <span class="MathJax" id="MathJax-Element-27-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-351" style="width: 0.891em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.788em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.585em, 1000em, 2.523em, -0.491em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-352"><span class="msubsup" id="MathJax-Span-353"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.923em, 1000em, 2.716em, -0.491em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-354" style="font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-355" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.791em; vertical-align: -0.238em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-27">s_i</script>. <span class="MathJax" id="MathJax-Element-31-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-392" style="width: 0.891em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.788em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.586em, 1000em, 2.523em, -0.477em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-393"><span class="msubsup" id="MathJax-Span-394"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.714em, -0.477em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-395" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-396" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.79em; vertical-align: -0.238em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-31">c_i</script> is simply a weighted sum <span class="MathJax" id="MathJax-Element-33-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-402" style="width: 7.078em; display: inline-block;"><span style="display: inline-block; position: relative; width: 6.363em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.415em, 1000em, 3.145em, -0.477em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-403"><span class="msubsup" id="MathJax-Span-404"><span style="display: inline-block; position: relative; width: 0.751em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.714em, -0.477em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-405" style="font-family: STIXGeneral-Italic;">c</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.45em;"><span class="mi" id="MathJax-Span-406" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-407" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">=</span><span class="munderover" id="MathJax-Span-408" style="padding-left: 0.313em;"><span style="display: inline-block; position: relative; width: 2.158em; height: 0px;"><span style="position: absolute; clip: rect(1.548em, 1000em, 2.907em, -0.449em); top: -2.477em; left: 0em;"><span class="mo" id="MathJax-Span-409" style="font-family: STIXGeneral-Regular; vertical-align: -0.002em;">∑</span><span style="display: inline-block; width: 0px; height: 2.477em;"></span></span><span style="position: absolute; clip: rect(1.678em, 1000em, 2.477em, -0.512em); top: -2.797em; left: 0.957em;"><span class="texatom" id="MathJax-Span-410"><span class="mrow" id="MathJax-Span-411"><span class="mi" id="MathJax-Span-412" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; clip: rect(1.662em, 1000em, 2.624em, -0.594em); top: -2.012em; left: 0.957em;"><span class="texatom" id="MathJax-Span-413"><span class="mrow" id="MathJax-Span-414"><span class="mi" id="MathJax-Span-415" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.001em;"></span></span><span class="mo" id="MathJax-Span-416" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">=</span><span class="mn" id="MathJax-Span-417" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-418" style="padding-left: 0.188em;"><span style="display: inline-block; position: relative; width: 1.089em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.714em, -0.49em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-419" style="font-family: STIXGeneral-Italic;">a</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.563em;"><span class="texatom" id="MathJax-Span-420"><span class="mrow" id="MathJax-Span-421"><span class="mi" id="MathJax-Span-422" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-423" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.001em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-424"><span style="display: inline-block; position: relative; width: 0.807em; height: 0px;"><span style="position: absolute; clip: rect(1.682em, 1000em, 2.712em, -0.488em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-425" style="font-family: STIXGeneral-Italic;">h</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.507em;"><span class="mi" id="MathJax-Span-426" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.001em;"></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.671em; vertical-align: -0.554em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-33">c_i = \sum_{j=1}^{L} a_{ij}h_j</script> of the encodings of all the words in the input, with each weight <span class="MathJax" id="MathJax-Element-34-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-427" style="width: 1.266em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.126em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.586em, 1000em, 2.661em, -0.49em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-428"><span class="msubsup" id="MathJax-Span-429"><span style="display: inline-block; position: relative; width: 1.089em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.714em, -0.49em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-430" style="font-family: STIXGeneral-Italic;">a</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.563em;"><span class="texatom" id="MathJax-Span-431"><span class="mrow" id="MathJax-Span-432"><span class="mi" id="MathJax-Span-433" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-434" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.001em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.943em; vertical-align: -0.391em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-34">a_{ij}</script> for each encoder hidden state <span class="MathJax" id="MathJax-Element-35-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-435" style="width: 0.953em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.845em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.344em, 1000em, 2.661em, -0.488em); top: -2.196em; left: 0em;"><span class="mrow" id="MathJax-Span-436"><span class="msubsup" id="MathJax-Span-437"><span style="display: inline-block; position: relative; width: 0.807em; height: 0px;"><span style="position: absolute; clip: rect(1.682em, 1000em, 2.712em, -0.488em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-438" style="font-family: STIXGeneral-Italic;">h</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.507em;"><span class="mi" id="MathJax-Span-439" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.001em;"></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.212em; vertical-align: -0.391em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-35">h_j</script> computed by the softmax <span class="MathJax" id="MathJax-Element-36-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-440" style="width: 9.141em; display: inline-block;"><span style="display: inline-block; position: relative; width: 8.221em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.257em, 1000em, 3.505em, -0.49em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-441"><span class="msubsup" id="MathJax-Span-442"><span style="display: inline-block; position: relative; width: 1.089em; height: 0px;"><span style="position: absolute; clip: rect(1.924em, 1000em, 2.714em, -0.49em); top: -2.534em; left: 0em;"><span class="mi" id="MathJax-Span-443" style="font-family: STIXGeneral-Italic;">a</span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span><span style="position: absolute; top: -2.159em; left: 0.563em;"><span class="texatom" id="MathJax-Span-444"><span class="mrow" id="MathJax-Span-445"><span class="mi" id="MathJax-Span-446" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">i</span><span class="mi" id="MathJax-Span-447" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.001em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span></span></span><span class="mo" id="MathJax-Span-448" style="font-family: STIXGeneral-Regular; padding-left: 0.313em;">=</span><span class="mfrac" id="MathJax-Span-449" style="padding-left: 0.313em;"><span style="display: inline-block; position: relative; width: 5.525em; height: 0px; margin-right: 0.12em; margin-left: 0.12em;"><span style="position: absolute; clip: rect(1.657em, 1000em, 2.687em, -0.489em); top: -2.934em; left: 50%; margin-left: -1.886em;"><span class="mrow" id="MathJax-Span-450"><span class="mi" id="MathJax-Span-451" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">exp</span><span class="mo" id="MathJax-Span-452" style="font-size: 70.7%;"></span><span class="texatom" id="MathJax-Span-453" style="padding-left: 0.188em;"><span class="mrow" id="MathJax-Span-454"><span class="mo" id="MathJax-Span-455" style="font-size: 70.7%;"></span></span></span><span class="mo" id="MathJax-Span-456" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-457"><span style="display: inline-block; position: relative; width: 1.179em; height: 0px;"><span style="position: absolute; clip: rect(1.827em, 1000em, 2.487em, -0.495em); top: -2.309em; left: 0em;"><span class="mi" id="MathJax-Span-458" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; top: -2.09em; left: 0.338em;"><span class="texatom" id="MathJax-Span-459"><span class="mrow" id="MathJax-Span-460"><span class="mi" id="MathJax-Span-461" style="font-size: 50%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-462" style="font-size: 50%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-463" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span><span class="mo" id="MathJax-Span-464" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">⋅</span><span class="msubsup" id="MathJax-Span-465"><span style="display: inline-block; position: relative; width: 0.616em; height: 0px;"><span style="position: absolute; clip: rect(1.657em, 1000em, 2.484em, -0.493em); top: -2.309em; left: 0em;"><span class="mi" id="MathJax-Span-466" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">h</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; top: -2.09em; left: 0.394em;"><span class="mi" id="MathJax-Span-467" style="font-size: 50%; font-family: STIXGeneral-Italic;">j<span style="display: inline-block; overflow: hidden; height: 1px; width: 0em;"></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span><span class="mo" id="MathJax-Span-468" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; clip: rect(1.468em, 1000em, 2.693em, -0.466em); top: -1.721em; left: 50%; margin-left: -2.703em;"><span class="mrow" id="MathJax-Span-469"><span class="munderover" id="MathJax-Span-470"><span style="display: inline-block; position: relative; width: 1.573em; height: 0px;"><span style="position: absolute; clip: rect(1.602em, 1000em, 2.662em, -0.466em); top: -2.309em; left: 0em;"><span class="mo" id="MathJax-Span-471" style="font-size: 70.7%; font-family: STIXGeneral-Regular; vertical-align: -0.002em;">∑</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; clip: rect(1.701em, 1000em, 2.365em, -0.511em); top: -2.541em; left: 0.676em;"><span class="mi" id="MathJax-Span-472" style="font-size: 50%; font-family: STIXGeneral-Italic;">L<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.002em;"></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span><span style="position: absolute; clip: rect(1.686em, 1000em, 2.37em, -0.5em); top: -1.986em; left: 0.676em;"><span class="texatom" id="MathJax-Span-473"><span class="mrow" id="MathJax-Span-474"><span class="mi" id="MathJax-Span-475" style="font-size: 50%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.009em;"></span></span><span class="mo" id="MathJax-Span-476" style="font-size: 50%; font-family: STIXGeneral-Regular;">=</span><span class="mn" id="MathJax-Span-477" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span><span class="mi" id="MathJax-Span-478" style="font-size: 70.7%; font-family: STIXGeneral-Regular; padding-left: 0.265em;">exp</span><span class="mo" id="MathJax-Span-479" style="font-size: 70.7%;"></span><span class="mo" id="MathJax-Span-480" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">(</span><span class="msubsup" id="MathJax-Span-481"><span style="display: inline-block; position: relative; width: 1.179em; height: 0px;"><span style="position: absolute; clip: rect(1.827em, 1000em, 2.487em, -0.495em); top: -2.309em; left: 0em;"><span class="mi" id="MathJax-Span-482" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">s</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; top: -2.09em; left: 0.338em;"><span class="texatom" id="MathJax-Span-483"><span class="mrow" id="MathJax-Span-484"><span class="mi" id="MathJax-Span-485" style="font-size: 50%; font-family: STIXGeneral-Italic;">i</span><span class="mo" id="MathJax-Span-486" style="font-size: 50%; font-family: STIXGeneral-Regular;">−</span><span class="mn" id="MathJax-Span-487" style="font-size: 50%; font-family: STIXGeneral-Regular;">1</span></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span><span class="mo" id="MathJax-Span-488" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">⋅</span><span class="msubsup" id="MathJax-Span-489"><span style="display: inline-block; position: relative; width: 0.729em; height: 0px;"><span style="position: absolute; clip: rect(1.657em, 1000em, 2.484em, -0.493em); top: -2.309em; left: 0em;"><span class="mi" id="MathJax-Span-490" style="font-size: 70.7%; font-family: STIXGeneral-Italic;">h</span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; top: -2.09em; left: 0.394em;"><span class="mi" id="MathJax-Span-491" style="font-size: 50%; font-family: STIXGeneral-Italic;">k<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.009em;"></span></span><span style="display: inline-block; width: 0px; height: 2.196em;"></span></span></span></span><span class="mo" id="MathJax-Span-492" style="font-size: 70.7%; font-family: STIXGeneral-Regular;">)</span></span><span style="display: inline-block; width: 0px; height: 2.309em;"></span></span><span style="position: absolute; clip: rect(0.831em, 1000em, 1.239em, -0.507em); top: -1.29em; left: 0em;"><span style="border-left-width: 5.525em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0em;"></span><span style="display: inline-block; width: 0px; height: 1.07em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 2.245em; vertical-align: -0.953em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-36">a_{ij}= \frac { \exp⁡(s_{i-1} \cdot h_j)} {\sum_{k=1}^L \exp (s_{i-1} \cdot h_k )}</script>. Here, the dot between the current decoder hidden state and an encoder hidden state is any function of their similarity (the original paper uses an addition and a single neural layer, however, the simple dot-product is commonly used), and the softmax turns all these similarities into a probability distribution.</p>
<p>This "attention mechanism" did not only allow for better translations, it made the interprebility of the translation results possible. By inspecting which words had the highest attention score at every stage of the translation, we can know which words were the most important to generating every other word. (Image 3 has a demonstration of this.) Attention mechanisms were a revolution in machine translation, with BLEU scores for English to French translation improved from 17 with a raw LSTM model to 26, just by adding an attention mechanism.</p>
<p style="text-align: center;"><img src="./assets/projects/nmt/resources/71124519F72894D50AFF62A073FD8A4A.png" alt="Screen Shot 2020-09-15 at 8.19.59 PM.png" width="200"><br>
Image from Bahdanau et al's paper [7]</p>
<h3>Transformers</h3>
<p>The latest great breakthrough in Natural Language Processing and Neural Machine Translation was the 2017 introduction of the <strong>Transformer</strong>. Given the importance of attention mechanisms to good translation results, researchers at Google Brain suspected that you could do away with the LSTM altogether and simply perform translation and language modeling with a series of stacked, repeated attention mechianisms. There were good reasons for this shift: Deep Learning was being made more effective only because GPUs were allowing greater data parallelism. LSTMs, however, operate sequentially and depend on its their output at a previous time frame (they are "autoregressive"). This means that there is no way to process all the words in sentence at once - the system must wait until previous word was processed before going on to the next one. This turned out to be a bottleneck preventing better language modeling and translation results.</p>
<p>The transformer model uses a stacked set of <strong>self-attention</strong> units, which are attention cells where the current word and the word being attended to are both in the same sequence. Recall that an attention output is a weighted sum of the inputs attended to, with each input weighted by its simiarlity with the target. In self-attention, the target and the inputs are one and the same. Thus, the self-attention mechanism essentially "reformulates" the embeddings of each word as an interpolation of the other words in the sentence that this word is most connected to. This "reformulation" is performed multiple times (6 in the original Transformer paper) and allows the embeddings to be regenerated as "contextual" embeddings, that is, embeddings which contain information not only about the word in isolation, but its relation to all other words (and all other words' relation to all other words, and so on). These self-attention units are interspersed with a feedforward network each time which "scrambles" the reformulation so that the most salient aspects can be picked out by the next layer.</p>
<p>In order to perform translation, the model also uses a decoder which has the same stacked-self attention architecture as the encoder, with two important differences: first, the decoder has, in addition to self-attention and feed-forward units, encoder-attention units which allows it to recieve the text encoding performed by the encoder, and secondly, the decoder's is not allowed to "cheat" and look at words it hasn't generated yet. As a fully end-to-end, purely attention-based, parallelizeable system, the transformer was able to be trained at a fraction of the time and memory requirements of LSTMs, while achieving significantly higher BLEU compared to the best LSTM translation systems at the time (in their paper, 28.4 vs 26 for English to German Translation).</p>
<p>Transformers are now the dominant paradigm in NLP and Neural Machine Translation, having ended the long-time dominance of LSTMs in the field. It is now the model of choice in almost all NLP applications. Before 2016, Google Translate used a statistical translation system ultimately based on n-grams. From 2016 to 2018, Google Translate used a large, bi-directional, 8-layer LSTM system trained on enormous amounts of parallel web text. Since 2018, Google Translate fully uses the Transformer as its foundational architecture. Transformers can be used for language modeling as well. The transformer encoder, with some modifications, can be its own stand-alone language model which is currently the most powerful language model for general applications, the famed <strong>BERT</strong>. The transformer decoder, similary, is currently the most powerful langauge model for the particular application of text generation, the famed <strong>GPT-1/2/3</strong>.</p>
<p style="text-align: center;"><img src="./assets/projects/nmt/resources/A63B1533003552FECFDE4131D63016AF.png" alt="DAFC8ACC59732077D298E53F967404E0.png" width="200"></p>
<h2>References</h2>
<p>[1] F Rosenblatt. "The Perceptron: A Probalistic Model For Information Storage And Organization In The Brain". <em>Psychological Review</em>, 1958.<br>
[2] R Williams, and D Zipster. "Gradient-Based Learning Algorithms for Recurrent Networks and Their Computational Complexity". Chapter in "Backpropagation: Theory, Architectures, and Applications", 1992.<br>
[3] S Hochreiter, and J Schmidhuber. "Long Short-Term Memory". <em>Neural Computation</em>, 1997.<br>
[4] H Ney, U Essen, and R Kneser. "On Structuring Probabilistic Dependences in Stochastic Language Modelling". <em>Computer Speech &amp; Language</em>, 1994.<br>
[5] Y Bengio, R Ducharme, P Vincent, and C Jauvin. "A Neural Probabilistic Language Model". <em>Journal of Machine Learning Research</em>, 2003.<br>
[6] I Sutskever, O Vinyals, and Q Le. "Sequence to Sequence Learning with Neural Networks". <em>NIPS</em>, 2014.<br>
[7] D Bahdanau, K Cho, and Y Bengio. "Neural Machine Translation By Jointly Learning to Align And Translate". <em>ICLR</em>, 2014.<br>
[8] A Vaswani, et al. "Attention is all You Need". <em>NIPS</em>, 2017</p>
<h2>Images</h2>
<h4>Image 1: Example of n-grams</h4>
<p style="text-align: center;"><img src="./assets/projects/nmt/resources/55FDB083DF563126B5195C339908EB8D.png" alt="B6E7DBD846B8641572753BAFAC8513E4.png" width="300"></p>
<h4>Image 2: Word Embeddings encode semantically meaningful representations of words as <span class="MathJax" id="MathJax-Element-22-Frame" role="textbox" aria-readonly="true" style=""><nobr><span class="math" id="MathJax-Span-311" style="width: 0.641em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.563em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.682em, 1000em, 2.716em, -0.492em); top: -2.534em; left: 0em;"><span class="mrow" id="MathJax-Span-312"><span class="mi" id="MathJax-Span-313" style="font-family: STIXGeneral-Italic;">d<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.027em;"></span></span></span><span style="display: inline-block; width: 0px; height: 2.534em;"></span></span></span><span style="border-left-width: 0em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.898em; vertical-align: -0.077em;"></span></span></nobr></span><script type="math/tex" id="MathJax-Element-22">d</script> (say 100) dimensional vectors</h4>
<p style="text-align: center;"><img src="./assets/projects/nmt/resources/FE2D7681F22EE98EFCB6D1B4DA9BE051.png" alt="1_gcC7b_v7OKWutYN1NAHyMQ.png" width="300"></p>
<h4>Image 3: Attention Mechanisms Allow us to Interpret Machine Translated Outputs</h4>
<p style="text-align: center;"><img src="./assets/projects/nmt/resources/3BB8FDCF0807A93F0B27BA03AF9C5886.png" alt="Screen Shot 2020-09-15 at 8.56.19 PM.png" width="400"><br>
Image from Bahdanau et al's paper [7]</p>
</div></div>
      <script></script>